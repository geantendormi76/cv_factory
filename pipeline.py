# æ–‡ä»¶: pipeline.py (V2.0 - å¥å£®æ€§å¼ºåŒ–ç‰ˆ)
# èŒè´£: ä½œä¸ºæ¨¡å‹å·¥å‚çš„ä¸­å¤®åè°ƒå™¨ï¼Œæä¾›æ¸…æ™°çš„é”™è¯¯æŠ¥å‘Šå’Œçµæ´»çš„è·¯å¾„å¤„ç†ï¼Œ
#       è§£æå®éªŒé…ç½®ï¼Œå¹¶æŒ‰é¡ºåºé©±åŠ¨æ•´ä¸ªç«¯åˆ°ç«¯çš„è®­ç»ƒæµæ°´çº¿ã€‚

import argparse
import json
import yaml
import sys
import importlib
from pathlib import Path
from typing import Dict, Any

try:
    from pydantic import BaseModel, ValidationError
except ImportError:
    print("é”™è¯¯: æ ¸å¿ƒä¾èµ– pydantic æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install pydantic")
    sys.exit(1)

# [IMPROVEMENT] é…ç½®æ¨¡å‹ç°åœ¨åªè´Ÿè´£ç»“æ„å’Œç±»å‹ï¼Œä¸è´Ÿè´£è·¯å¾„å­˜åœ¨æ€§æ ¡éªŒã€‚
# æ ¡éªŒçš„èŒè´£è½¬ç§»åˆ°æ‹¥æœ‰æ›´å¤šä¸Šä¸‹æ–‡çš„ Orchestrator ä¸­ã€‚
class PipelineConfig(BaseModel):
    project_name: str
    run_name: str
    task_type: str
    source_data_dir: str # ä» DirectoryPath æ”¹ä¸º strï¼Œä»¥å¢åŠ çµæ´»æ€§
    base_model: str
    class_names: Dict[int, str]
    hyperparameters: Dict[str, Any]
    onnx_output_name: str


class Orchestrator:
    def __init__(self, config_path: Path):
        print(f"--- [1/5] åˆå§‹åŒ–æµæ°´çº¿: åŠ è½½é…ç½®æ–‡ä»¶ ---")
        if not config_path.is_file():
            raise FileNotFoundError(f"æŒ‡å®šçš„é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        
        self.project_root = Path(__file__).resolve().parent
        
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                raw_config = yaml.safe_load(f)
            self.config = PipelineConfig.model_validate(raw_config)
            print(f"âœ… é…ç½®æ–‡ä»¶ '{config_path.name}' ç»“æ„éªŒè¯æˆåŠŸã€‚")
        except ValidationError as e:
            print(f"âŒ é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œè¯·æ£€æŸ¥ä»¥ä¸‹é—®é¢˜:\n{e}")
            raise
        except Exception as e:
            print(f"âŒ é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
            raise
        
        # [ROBUSTNESS] æ–°å¢ç‹¬ç«‹çš„è·¯å¾„è§£æå’ŒéªŒè¯æ­¥éª¤
        self._resolve_and_validate_paths()

        self.processed_data_dir = self.project_root / "data" / "processed" / f"{self.config.run_name}_dataset"
        self.run_dir = self.project_root / "runs" / self.config.project_name / self.config.run_name
        self.temp_yolo_config_path = None

    def _resolve_and_validate_paths(self):
        """[ROBUSTNESS] æ™ºèƒ½è§£æå¹¶éªŒè¯æ‰€æœ‰å…³é”®è·¯å¾„ã€‚"""
        print("   - æ­£åœ¨éªŒè¯è·¯å¾„...")
        
        # å¤„ç† source_data_dir
        source_path = Path(self.config.source_data_dir)
        if not source_path.is_absolute():
            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œåˆ™ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•è¿›è¡Œè§£æ
            source_path = self.project_root / source_path
        
        if not source_path.exists() or not source_path.is_dir():
            raise FileNotFoundError(f"å…³é”®é”™è¯¯: è§£æåçš„æºæ•°æ®ç›®å½•ä¸å­˜åœ¨æˆ–ä¸æ˜¯ä¸€ä¸ªç›®å½•!\n   - è§£æè·¯å¾„: {source_path}")
        
        # å°†éªŒè¯åçš„ç»å¯¹è·¯å¾„å†™å›é…ç½®å¯¹è±¡ï¼Œä¾›åç»­ä½¿ç”¨
        self.config.source_data_dir = source_path
        print(f"   - æºæ•°æ®ç›®å½•éªŒè¯æˆåŠŸ: {self.config.source_data_dir}")

    def _prepare_environment(self):
        """å‡†å¤‡è¿è¡Œç¯å¢ƒï¼Œåˆ›å»ºå¿…è¦çš„ç›®å½•ã€‚"""
        print(f"\n--- [2/5] å‡†å¤‡è¿è¡Œç¯å¢ƒ ---")
        self.processed_data_dir.mkdir(parents=True, exist_ok=True)
        self.run_dir.mkdir(parents=True, exist_ok=True)
        print(f"   - æ•°æ®å¤„ç†ç›®å½•: {self.processed_data_dir}")
        print(f"   - è®­ç»ƒè¾“å‡ºç›®å½•: {self.run_dir}")
        print("âœ… ç¯å¢ƒå‡†å¤‡å°±ç»ªã€‚")

    def _generate_yolo_config(self) -> Path:
        """æ ¹æ®å®éªŒé…ç½®åŠ¨æ€ç”Ÿæˆä¸€ä¸ªä¸´æ—¶çš„YOLOè®­ç»ƒé…ç½®æ–‡ä»¶ã€‚"""
        yolo_params = self.config.hyperparameters.copy()
        
        yolo_params['model'] = self.config.base_model
        yolo_params['project'] = str(self.project_root / "runs" / self.config.project_name)
        yolo_params['name'] = self.config.run_name
        yolo_params['data'] = str(self.processed_data_dir / "dataset.yaml")
        
        self.temp_yolo_config_path = self.run_dir / "_temp_yolo_config.yaml"
        with open(self.temp_yolo_config_path, 'w', encoding='utf-8') as f:
            yaml.dump(yolo_params, f, sort_keys=False, allow_unicode=True)
        
        print(f"   - åŠ¨æ€ç”ŸæˆYOLOé…ç½®æ–‡ä»¶: {self.temp_yolo_config_path}")
        return self.temp_yolo_config_path

    def run_data_pipeline(self):
        """æ‰§è¡Œæ•°æ®å‡†å¤‡æµæ°´çº¿ã€‚"""
        print(f"\n--- [3/5] æ‰§è¡Œæ•°æ®å‡†å¤‡æµæ°´çº¿ ---")
        with open(self.project_root / "task_registry.json", 'r', encoding='utf-8') as f:
            registry = json.load(f)
        
        task_info = registry['tasks'].get(self.config.task_type)
        if not task_info:
            raise ValueError(f"ä»»åŠ¡ç±»å‹ '{self.config.task_type}' æœªåœ¨ task_registry.json ä¸­æ³¨å†Œã€‚")
        
        print(f"   - ä»»åŠ¡ç±»å‹: {self.config.task_type} -> {task_info['description']}")

        module = importlib.import_module(task_info['data_builder_module'])
        builder_func = getattr(module, task_info['data_builder_func'])
        
        builder_func(
            source_dir=self.config.source_data_dir,
            output_dir=self.processed_data_dir,
            class_names=self.config.class_names
        )
        print(f"âœ… æ•°æ®å‡†å¤‡æµæ°´çº¿æ‰§è¡ŒæˆåŠŸã€‚")

    def run_training_pipeline(self):
        """æ‰§è¡Œæ¨¡å‹è®­ç»ƒå’Œå¯¼å‡ºæµæ°´çº¿ã€‚"""
        print(f"\n--- [4/5] æ‰§è¡Œæ¨¡å‹è®­ç»ƒä¸å¯¼å‡ºæµæ°´çº¿ ---")
        yolo_config_path = self._generate_yolo_config()
        
        from trainer.trainer import Trainer
        
        trainer = Trainer(yolo_config_path)
        trainer.train()
        trainer.export_model(onnx_target_name=self.config.onnx_output_name)
        print(f"âœ… æ¨¡å‹è®­ç»ƒä¸å¯¼å‡ºæˆåŠŸã€‚")

    def _cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶ã€‚"""
        print(f"\n--- [5/5] æ¸…ç†ä¸´æ—¶æ–‡ä»¶ ---")
        if self.temp_yolo_config_path and self.temp_yolo_config_path.exists():
            self.temp_yolo_config_path.unlink()
            print(f"   - å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {self.temp_yolo_config_path}")
        print("âœ… æ¸…ç†å®Œæˆã€‚")

    def run(self):
        """æŒ‰é¡ºåºæ‰§è¡Œå®Œæ•´çš„ç«¯åˆ°ç«¯æµæ°´çº¿ã€‚"""
        try:
            self._prepare_environment()
            self.run_data_pipeline()
            self.run_training_pipeline()
        finally:
            self._cleanup()
        
        print("\n" + "="*80)
        print("ğŸ‰ğŸ‰ğŸ‰ æµæ°´çº¿æ‰§è¡ŒæˆåŠŸå®Œæˆï¼ ğŸ‰ğŸ‰ğŸ‰")
        print(f"   - è®­ç»ƒäº§ç‰©ä½äº: {self.run_dir}")
        print(f"   - æœ€ç»ˆONNXæ¨¡å‹ä½äº: {self.project_root / 'saved/models' / self.config.onnx_output_name}")
        print("="*80)

def main():
    parser = argparse.ArgumentParser(description="MHXY AI Model Factory - Central Pipeline")
    parser.add_argument(
        '-c', '--config',
        type=Path,
        required=True,
        help='æŒ‡å‘å®éªŒé…ç½®æ–‡ä»¶ (run_config.yaml) çš„è·¯å¾„'
    )
    args = parser.parse_args()

    try:
        orchestrator = Orchestrator(config_path=args.config)
        orchestrator.run()
    except Exception as e:
        # [ROBUSTNESS] å…³é”®æ”¹è¿›ï¼šæ‰“å°å®Œæ•´ã€è¯¦ç»†çš„é”™è¯¯è¿½æº¯ä¿¡æ¯ï¼
        print(f"\n--- âŒ æµæ°´çº¿æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿè‡´å‘½é”™è¯¯ ---")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == '__main__':
    main()