
import cv2
import numpy as np
from pathlib import Path
import sys
import argparse
import yaml

# --- è·¯å¾„é€‚é… ---
PROJECT_ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(PROJECT_ROOT))

try:
    from segment_anything import sam_model_registry, SamPredictor
except ImportError:
    print("âŒ é”™è¯¯: æœªå®‰è£… segment-anythingã€‚")
    sys.exit(1)

# --- é…ç½® ---
SAM_CHECKPOINT_PATH = PROJECT_ROOT / "models" / "sam_vit_h_4b8939.pth"
MODEL_TYPE = "vit_h"
DEVICE = "cuda"

# --- å…¨å±€å˜é‡ ---
input_points = []
input_labels = []

def print_usage():
    """æ‰“å°æ“ä½œæŒ‡å—"""
    print("\n" + "="*60)
    print("ğŸ®  SAM å¼ºåŠ›æŠ å›¾å·¥å…· (æ— å†²çªç‰ˆ) - æ“ä½œæŒ‡å—")
    print("="*60)
    print("ğŸ–±ï¸ ã€å·¦é”®ç‚¹å‡»ã€‘         æ·»åŠ  [æ­£å‘ç‚¹] (è¿™æ˜¯ç‰©ä½“)")
    print("ğŸ–±ï¸ ã€Ctrl + å·¦é”®ã€‘      æ·»åŠ  [è´Ÿå‘ç‚¹] (è¿™æ˜¯èƒŒæ™¯)")
    print("ğŸ–±ï¸ ã€é¼ æ ‡ä¸­é”®(æ»šè½®)ã€‘   æ·»åŠ  [è´Ÿå‘ç‚¹] (å¤‡ç”¨æ–¹æ¡ˆ)")
    print("-" * 60)
    print("âŒ¨ï¸ ã€S é”®ã€‘     ä¿å­˜å½“å‰æŠ å›¾")
    print("âŒ¨ï¸ ã€R é”®ã€‘     é‡ç½®å½“å‰é€‰æ‹©")
    print("âŒ¨ï¸ ã€A é”®ã€‘     <-- ä¸Šä¸€å¼ ")
    print("âŒ¨ï¸ ã€D é”®ã€‘     --> ä¸‹ä¸€å¼ ")
    print("âŒ¨ï¸ ã€Q é”®ã€‘     é€€å‡º")
    print("="*60 + "\n")

def mouse_callback(event, x, y, flags, param):
    global input_points, input_labels
    
    # 1. æ·»åŠ è´Ÿå‘ç‚¹ (èƒŒæ™¯)
    # é€»è¾‘: æŒ‰ä¸‹ä¸­é”®ï¼Œæˆ–è€… æŒ‰ä¸‹å·¦é”®çš„åŒæ—¶æŒ‰ä½äº†Ctrl
    if event == cv2.EVENT_MBUTTONDOWN or (event == cv2.EVENT_LBUTTONDOWN and (flags & cv2.EVENT_FLAG_CTRLKEY)):
        input_points.append([x, y])
        input_labels.append(0) # Label 0 = èƒŒæ™¯
        print(f"  â– æ·»åŠ è´Ÿå‘ç‚¹ (èƒŒæ™¯): ({x}, {y})")
        
    # 2. æ·»åŠ æ­£å‘ç‚¹ (ä¸»ä½“)
    # é€»è¾‘: ä»…æŒ‰ä¸‹å·¦é”® (ä¸”æ²¡æœ‰æŒ‰Ctrl)
    elif event == cv2.EVENT_LBUTTONDOWN:
        input_points.append([x, y])
        input_labels.append(1) # Label 1 = ä¸»ä½“
        print(f"  â• æ·»åŠ æ­£å‘ç‚¹ (ä¸»ä½“): ({x}, {y})")

def main():
    print_usage()
    
    raw_dir = PROJECT_ROOT / "data" / "raw" 
    output_base = PROJECT_ROOT / "data" / "assets" / "icons"
    
    if not raw_dir.exists():
        print(f"âŒ é”™è¯¯: å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {raw_dir}")
        return
    output_base.mkdir(parents=True, exist_ok=True)

    print("\nâ³ æ­£åœ¨åŠ è½½ SAM æ¨¡å‹ (è¯·ç¨å€™)...")
    try:
        sam = sam_model_registry[MODEL_TYPE](checkpoint=SAM_CHECKPOINT_PATH)
        sam.to(device=DEVICE)
        predictor = SamPredictor(sam)
        print("âœ… æ¨¡å‹åŠ è½½å®Œæ¯•ï¼")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return

    # åŠ è½½ç±»åˆ«å
    class_names = {}
    yaml_path = PROJECT_ROOT / "yolo.yaml"
    if yaml_path.exists():
        try:
            with open(yaml_path, 'r', encoding='utf-8') as f:
                cfg = yaml.safe_load(f)
                class_names = cfg.get('class_names', {})
        except: pass

    images = sorted(list(raw_dir.glob("*.png")) + list(raw_dir.glob("*.jpg")))
    if not images:
        print("âŒ ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡ï¼")
        return
        
    current_idx = 0
    total_images = len(images)
    
    while True:
        if current_idx < 0: current_idx = 0
        if current_idx >= total_images: current_idx = total_images - 1
        
        img_path = images[current_idx]
        print(f"\n[{current_idx+1}/{total_images}] æ­£åœ¨å¤„ç†: {img_path.name}")
        
        image = cv2.imread(str(img_path))
        if image is None: 
            print("   âš ï¸ æ— æ³•è¯»å–ï¼Œè·³è¿‡ã€‚")
            current_idx += 1
            continue
        
        predictor.set_image(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        
        # æ›´æ–°çª—å£æ ‡é¢˜æç¤º
        window_name = f"Extractor (Left:Add, Ctrl+Left:Remove)"
        cv2.namedWindow(window_name)
        cv2.setMouseCallback(window_name, mouse_callback)
        
        global input_points, input_labels
        input_points = []
        input_labels = []
        
        while True:
            vis = image.copy()
            mask = None
            
            # ç»˜åˆ¶ç‚¹
            for pt, label in zip(input_points, input_labels):
                # æ­£å‘ç‚¹=ç»¿è‰²å®å¿ƒï¼Œè´Ÿå‘ç‚¹=çº¢è‰²å®å¿ƒ
                color = (0, 255, 0) if label == 1 else (0, 0, 255)
                cv2.circle(vis, tuple(pt), 5, color, -1)
                # ç»™è´Ÿå‘ç‚¹åŠ ä¸ªç™½åœˆï¼Œæ›´æ˜æ˜¾
                if label == 0:
                    cv2.circle(vis, tuple(pt), 5, (255, 255, 255), 1)
            
            # å®æ—¶é¢„æµ‹
            if len(input_points) > 0:
                masks, scores, _ = predictor.predict(
                    point_coords=np.array(input_points),
                    point_labels=np.array(input_labels),
                    multimask_output=False
                )
                mask = masks[0]
                # ç»¿è‰²åŠé€æ˜é«˜äº®
                vis[mask] = vis[mask] * 0.5 + np.array([0, 255, 0]) * 0.5

            cv2.imshow(window_name, vis)
            key = cv2.waitKey(1) & 0xFF

            if key == ord('s'): # Save
                if mask is not None:
                    if class_names:
                        print("\nğŸ“‹ å¯é€‰ç±»åˆ«:")
                        for cid, cname in class_names.items():
                            print(f"   [{cid}] {cname}")
                    
                    try:
                        cls_id_str = input("ğŸ‘‰ è¯·è¾“å…¥ç±»åˆ«ID (æ•°å­—): ")
                        cls_id = int(cls_id_str)
                        cls_name = class_names.get(cls_id, "unknown")
                        
                        y_idx, x_idx = np.where(mask)
                        if len(y_idx) == 0: continue

                        y_min, y_max = y_idx.min(), y_idx.max()
                        x_min, x_max = x_idx.min(), x_idx.max()
                        
                        b, g, r = cv2.split(image)
                        alpha = (mask * 255).astype(np.uint8)
                        rgba = cv2.merge([b, g, r, alpha])
                        
                        crop = rgba[y_min:y_max+1, x_min:x_max+1]
                        
                        # æ–‡ä»¶åå¢åŠ æ—¶é—´æˆ³æˆ–éšæœºæ•°é˜²æ­¢è¦†ç›–
                        import time
                        save_name = f"{cls_id}_{cls_name}_{img_path.stem}_{int(time.time())}.png"
                        save_path = output_base / save_name
                        cv2.imwrite(str(save_path), crop)
                        print(f"âœ… æˆåŠŸä¿å­˜: {save_name}")
                        
                        input_points = []
                        input_labels = []
                        
                    except ValueError:
                        print("âŒ è¾“å…¥æ— æ•ˆ")
                else:
                    print("âš ï¸ è¯·å…ˆç‚¹å‡»ç‰©ä½“")

            elif key == ord('r'): # Reset
                input_points = []
                input_labels = []

            elif key == ord('d'): # Next
                current_idx += 1
                break
            
            elif key == ord('a'): # Prev
                current_idx -= 1
                break
                
            elif key == ord('q'): # Quit
                sys.exit(0)
        
        cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
