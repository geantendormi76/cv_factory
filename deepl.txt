=== é¡¹ç›®æ ¸å¿ƒæ–‡ä»¶ç»“æ„ ===

deepl
â”œâ”€â”€ base
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ config.json
â”œâ”€â”€ configs
â”‚   â”œâ”€â”€ main_config.yaml
â”‚   â”œâ”€â”€ synthesis_config.yaml
â”‚   â””â”€â”€ yolo_events_v1.yaml
â”œâ”€â”€ data_loader
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ classifier_loader.py
â”‚   â””â”€â”€ detector_loader.py
â”œâ”€â”€ logger
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ model
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ prepare_data.py
â”œâ”€â”€ py.py
â”œâ”€â”€ runs
â”‚   â”œâ”€â”€ yolo_events_v1_run
â”‚   â”‚   â””â”€â”€ args.yaml
â”‚   â””â”€â”€ yolo_synthetic_v3
â”‚       â””â”€â”€ args.yaml
â”œâ”€â”€ test.py
â”œâ”€â”€ tools
â”‚   â”œâ”€â”€ data_inspector.py
â”‚   â””â”€â”€ data_synthesizer.py
â”œâ”€â”€ train.py
â”œâ”€â”€ trainer
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ trainer.py
â””â”€â”€ utils
    â”œâ”€â”€ __init__.py
    â””â”€â”€ constants.py


=== æ ¸å¿ƒæ–‡ä»¶å†…å®¹ ===

================================================
FILE: base/__init__.py
================================================


================================================
FILE: config.json
================================================

{
  "project_name": "MHXY_AI_Model_Factory",
  "n_gpu": 1,
  "tasks": {
    "detector": {
        "description": "è®­ç»ƒYOLO11å®ä½“æ£€æµ‹å™¨ (æ¥è‡ªçœŸå®æ•°æ®)",
        "yolo_config_path": "yolo_events_v1.yaml",
        "data_builder_module": "data_loader.detector_loader",
        "data_builder_func": "build_yolo_dataset"
    },
    "classifier": {
      "description": "è®­ç»ƒYOLO11æˆ˜æ–—å•ä½åˆ†ç±»å™¨",
      "yolo_config_path": "classifier_config.yaml",
      "data_builder_module": "data_loader.classifier_loader",
      "data_builder_func": "generate_classifier_data"
    },
    "synthetic_generator": {
      "description": "ä½¿ç”¨èµ„äº§åº“ç”ŸæˆYOLO11æ£€æµ‹è®­ç»ƒæ•°æ®",
      "data_builder_module": "data_loader.synthetic_data_generator",
      "data_builder_func": "generate_synthetic_dataset",
      "config": {
        "num_images_to_generate": 10000,
        "max_instances_per_image": 20,
        "min_instances_per_image": 5
      }
    }
  },
  "data_paths": {
    "detector_source_dir": "data/raw/yolo_events_v1", 
    "detector_output_dir": "data/processed/yolo_events_v1_dataset",

    "classifier_asset_dir": "data/raw/assets_battle_units",
    "classifier_output_dir": "data/processed/battle_units_for_classification",
    
    "synthetic_assets_dir": "data/assets/foregrounds",
    "synthetic_backgrounds_dir": "data/assets/backgrounds",
    "synthetic_output_dir": "data/processed/synthetic_dataset"
  }
}
================================================
FILE: configs/main_config.yaml
================================================

# æ–‡ä»¶: configs/main_config.yaml (V_final - é»„é‡‘æ··åˆæ•°æ®å¾®è°ƒç‰ˆ)

# --- 1. æ ¸å¿ƒè®­ç»ƒè®¾ç½® ---
# ã€æ ¸å¿ƒèµ·ç‚¹ã€‘åŠ è½½æ‚¨ä¸Šä¸€è½®ç”¨300+çœŸå®æ•°æ®è®­ç»ƒå‡ºçš„æœ€å¼ºæ¨¡å‹ï¼
model: /home/zhz/deepl/runs/numbers_v1/locator_finetune_with_numbers_v1/weights/best.pt

# ã€æ ¸å¿ƒæ•°æ®ã€‘æŒ‡å‘æˆ‘ä»¬åˆšåˆšç”Ÿæˆçš„åˆæˆæ•°æ®é›†ã€‚æˆ‘ä»¬å°†åœ¨è¿™ä¸ªåŸºç¡€ä¸Šè¿›è¡Œæ•°æ®åˆå¹¶ã€‚
data: /home/zhz/deepl/data/processed/synthetic_locator_dataset/dataset.yaml

# ã€è°ƒæ•´ã€‘æ•°æ®é›†å¾ˆå¤§ï¼Œç»™è¶³å­¦ä¹ æ—¶é—´ï¼Œä½†patienceä¼šä¿æŠ¤æˆ‘ä»¬
epochs: 30
patience: 10

# ã€è°ƒæ•´ã€‘æ•°æ®é›†å˜å¤§ï¼Œå¯ä»¥é€‚å½“å¢åŠ æ‰¹é‡å¤§å°ä»¥åŠ é€Ÿè®­ç»ƒ
batch: 32
imgsz: 640
device: 0
workers: 8
project: /home/zhz/deepl/runs/
# ã€æ ¸å¿ƒã€‘ä¸ºè¿™æ¬¡å†³å®šæ€§çš„è®­ç»ƒèµ·ä¸€ä¸ªå…¨æ–°çš„åå­—ï¼
name: yolo_synthetic_v3
exist_ok: True

# --- 2. ä¼˜åŒ–å™¨ä¸å­¦ä¹ ç‡ ---
optimizer: auto
# ã€æ ¸å¿ƒå…³é”®ã€‘è¿™ä»ç„¶æ˜¯ä¸€æ¬¡å¾®è°ƒï¼Œä½¿ç”¨è¾ƒä½çš„å­¦ä¹ ç‡æ¥â€œç²¾é›•ç»†ç¢â€ï¼Œè€Œä¸æ˜¯â€œæ¨å€’é‡æ¥â€
lr0: 0.001
lrf: 0.01
momentum: 0.937
weight_decay: 0.0005
warmup_epochs: 3.0

# --- 3. æŸå¤±å‡½æ•°æƒé‡ (é’ˆå¯¹æ€§ä¼˜åŒ–) ---
# ã€ä¼˜åŒ–ã€‘é€‚å½“æé«˜åˆ†ç±»æŸå¤±çš„æƒé‡ï¼Œè®©æ¨¡å‹æ›´å…³æ³¨è¯†åˆ«å¯¹ç¨€ç¼ºç±»åˆ«
box: 7.5
cls: 1.0  # ä» 0.5 æå‡åˆ° 1.0
dfl: 1.5

# --- 4. æ•°æ®å¢å¼º (ä¿æŒå¼ºåŒ–ç‰ˆ) ---
degrees: 20.0
translate: 0.2
scale: 0.2  # é€‚å½“å‡å°ç¼©æ”¾èŒƒå›´ï¼Œä¿æŠ¤å°ç›®æ ‡
fliplr: 0.5
mosaic: 1.0
hsv_h: 0.015
hsv_s: 0.7
hsv_v: 0.4
================================================
FILE: configs/synthesis_config.yaml
================================================

# æ–‡ä»¶: configs/synthesis_config.yaml (V3.0 - ç²¾ç¡®ROIé”šç‚¹ç‰ˆ)

# --- 1. æ ¸å¿ƒç”Ÿæˆå‚æ•° ---
num_images_to_generate: 10000  # ä¸ºç¨€ç¼ºç±»åˆ«ç”Ÿæˆå……è¶³çš„æ•°æ®
output_image_size: [800, 600]

# --- 2. æˆ˜æ–—å•ä½åˆæˆå‚æ•° ---
unit_density:
  min_enemy_units: 3
  max_enemy_units: 10
  # å‹æ–¹å•ä½å›ºå®šä¸º1ä¸ªç©å®¶+1ä¸ªå® ç‰©

# --- 3. ã€æ ¸å¿ƒæ›´æ–°ã€‘é«˜ä¿çœŸæ”¾ç½®é»„é‡‘æ³•åˆ™ (åŸºäºæ‚¨çš„ç²¾ç¡®ROI) ---
placement_rules:
  # æˆ˜æœ¯æ§½ä½ROIï¼šæ¯ä¸ªå•ä½å°†åœ¨å…¶æŒ‡å®šçš„çŸ©å½¢æ¡†å†…éšæœºæ”¾ç½®
  formation_slots:
    enemy_back:
      - [30, 187, 130, 282]
      - [111, 145, 207, 240]
      - [144, 46, 303, 192]
      - [254, 43, 364, 138]
      - [320, 13, 453, 111]
    enemy_front:
      - [83, 261, 202, 359]
      - [148, 180, 272, 295]
      - [238, 147, 356, 253]
      - [311, 81, 428, 203]
      - [398, 56, 517, 161]
    friendly_front: # For pets
      - [304, 394, 406, 497]
      - [366, 343, 474, 442]
      - [441, 288, 553, 387]
      - [512, 237, 621, 346]
      - [578, 185, 703, 290]
    friendly_back:  # For players
      - [375, 412, 472, 556]
      - [438, 364, 546, 517]
      - [513, 313, 616, 446]
      - [596, 270, 707, 413]
      - [666, 223, 766, 363]
  
  overlap_threshold: 0.05 # å…è®¸çš„é‡å ç‡å¯ä»¥è°ƒå¾—æ›´ä½ï¼Œå› ä¸ºä½ç½®å·²ç»å¾ˆç²¾ç¡®

# --- 4. çŠ¶æ€æŒ‡ç¤ºå™¨å…³è”è§„åˆ™ (ç²¾ç¡®ç‰ˆ) ---
healthbar_association:
  enabled: true
  probability: 0.95
  vertical_offset: -30 # å›ºå®šå‘ä¸Šåç§»30åƒç´ 
  body_center_jitter_ratio: 0.4
  
damage_number_association:
  enabled: true
  probability: 0.8
  heal_probability: 0.3 
  body_center_jitter_ratio: 0.4

# --- 5. UIé®æŒ¡å¢å¼º (ç²¾ç¡®ç‰ˆ) ---
ui_occlusion:
  enabled: true
  probability: 0.5
  # æŠ€èƒ½UIèƒŒæ™¯çš„ç»å¯¹ä½ç½®
  panel_roi: [303, 135, 495, 463]
  # æŠ€èƒ½å›¾æ ‡ç›¸å¯¹äº panel_roi å·¦ä¸Šè§’çš„åç§»ä½ç½®
  skill_slots_relative:
    - [30, 42, 69, 77]
    - [124, 40, 164, 79]
    - [29, 87, 70, 127]
    - [124, 85, 162, 125]
    - [29, 131, 71, 170]
    - [122, 130, 163, 173]
  num_skills_to_show_range: [4, 6]

# --- 6. èµ„äº§çº¦å®š (ä¿æŒä¸å˜) ---
asset_conventions:
  default_facing_direction: "right"
================================================
FILE: configs/yolo_events_v1.yaml
================================================

# æ–‡ä»¶: configs/yolo_events_v1.yaml
# èŒè´£: [æœ€ç»ˆçš„å•ä¸€äº‹å®æ¥æº] å®šä¹‰æœ¬æ¬¡ä»»åŠ¡çš„æ‰€æœ‰é…ç½®ã€‚
#       æœåŠ¡äº prepare_data.py (è¯»å– names) å’Œ train.py (è¯»å–æ‰€æœ‰å‚æ•°)ã€‚

# --- 1. æ ¸å¿ƒè®­ç»ƒè®¾ç½® ---
# ã€æ ¸å¿ƒèµ·ç‚¹ã€‘ä»ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹å¼€å§‹
model: yolov8n.pt  # æˆ–è€… /home/zhz/deepl/models/yolov8n.pt

# ã€æ ¸å¿ƒæ•°æ®ã€‘æŒ‡å‘æ•°æ®å‡†å¤‡è„šæœ¬å°†è¦ç”Ÿæˆçš„ dataset.yaml
# è¯·ä½¿ç”¨ç»å¯¹è·¯å¾„ä»¥ä¿è¯å¥å£®æ€§
data: /home/zhz/deepl/data/processed/yolo_events_v1_dataset/dataset.yaml

# ã€æ ¸å¿ƒè®­ç»ƒå‚æ•°ã€‘
epochs: 200
patience: 30
batch: 8
imgsz: 640
device: 0
workers: 8
project: /home/zhz/deepl/runs/
name: yolo_events_v1_run
exist_ok: True

# --- 2. ä¼˜åŒ–å™¨ä¸å­¦ä¹ ç‡ ---
optimizer: auto
lr0: 0.01
lrf: 0.01

# --- 3. ç±»åˆ«åç§° (ä¾› prepare_data.py ä½¿ç”¨) ---
# ã€æ ¸å¿ƒã€‘è¿™ä¸ªåˆ—è¡¨æ˜¯æ•°æ®è½¬æ¢çš„ä¾æ®ï¼Œå¿…é¡»ä¸ä¿®å¤åçš„ .json æ ‡ç­¾ä¸€è‡´ã€‚
names:
  0: ä¼¤å®³æ•°å€¼
  1: æ¢å¤æ•°å€¼
  2: è¡€æ¡
================================================
FILE: data_loader/__init__.py
================================================


================================================
FILE: data_loader/classifier_loader.py
================================================

# æ–‡ä»¶: data_loader/classification_dataset_builder.py (é€‚é…ç‰ˆ)
import cv2
import numpy as np
from pathlib import Path
import random
import shutil
from tqdm import tqdm
import sys
from typing import Dict

PROJECT_ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(PROJECT_ROOT))

def generate_classifier_data(config: Dict):
    """
    é€šè¿‡å¢å¼ºç´ æï¼Œç”ŸæˆYOLOåˆ†ç±»ä»»åŠ¡çš„æ•°æ®é›†ã€‚
    :param config: ä»ä¸»config.jsonåŠ è½½çš„å®Œæ•´é…ç½®å­—å…¸ã€‚
    """
    data_paths = config['data_paths']
    asset_dir = Path(data_paths['classifier_asset_dir'])
    output_dir = Path(data_paths['classifier_output_dir'])
    
    print(f"--- [æ•°æ®æ„å»º] å¼€å§‹ç”Ÿæˆåˆ†ç±»å™¨æ•°æ®: {asset_dir} ---")

    if not asset_dir.is_dir():
        print(f"âš ï¸ è­¦å‘Š: ç´ æç›®å½• {asset_dir} ä¸å­˜åœ¨ï¼Œè·³è¿‡æ•°æ®å‡†å¤‡ã€‚")
        print("   è¯·å°†åˆ†ç±»ç´ ææ”¾å…¥è¯¥ç›®å½•ã€‚")
        return

    # ... æ­¤å¤„ç²˜è´´æ‚¨åŸæ¥çš„ 01_data_generator.py çš„æ ¸å¿ƒé€»è¾‘ ...
    # ä¸ºäº†ä¿æŒå®Œæ•´æ€§ï¼Œæˆ‘å°†æ•´ä¸ªå‡½æ•°é€»è¾‘å¤åˆ¶è¿‡æ¥
    SAMPLES_PER_CLASS = 300
    SCALE_RANGE = (0.8, 1.2)
    ROTATION_RANGE = (-15, 15)
    FLIP_CHANCE = 0.5
    
    assets = {}
    class_pinyin_names = [d.name for d in asset_dir.iterdir() if d.is_dir()]
    for pinyin_name in class_pinyin_names:
        assets[pinyin_name] = [cv2.imread(str(p), cv2.IMREAD_UNCHANGED) for p in (asset_dir / pinyin_name).glob("*.png")]
        assets[pinyin_name] = [img for img in assets[pinyin_name] if img is not None]
    
    if not assets:
        print(f"âŒ é”™è¯¯: åœ¨ {asset_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„ç´ æã€‚")
        return

    if output_dir.exists():
        shutil.rmtree(output_dir)
    
    for pinyin_name in assets.keys():
        (output_dir / pinyin_name).mkdir(parents=True, exist_ok=True)

    for pinyin_name, asset_list in tqdm(assets.items(), desc="ç”Ÿæˆç±»åˆ«"):
        if not asset_list: continue
        for i in range(SAMPLES_PER_CLASS):
            base_asset = random.choice(asset_list)
            augmented_asset = augment_asset(base_asset, SCALE_RANGE, ROTATION_RANGE, FLIP_CHANCE)
            if augmented_asset is None: continue
            final_sample = augmented_asset[:,:,:3]
            save_path = output_dir / pinyin_name / f"{pinyin_name}_{i:04d}.png"
            cv2.imwrite(str(save_path), final_sample)

    print(f"âœ… [æ•°æ®æ„å»º] åˆ†ç±»æ•°æ®é›†æ„å»ºæˆåŠŸï¼\n   è¾“å‡ºç›®å½•: {output_dir}")

def augment_asset(asset, scale_range, rotation_range, flip_chance):
    scale = random.uniform(*scale_range)
    h, w = asset.shape[:2]
    new_h, new_w = int(h * scale), int(w * scale)
    if new_h <= 0 or new_w <= 0: return None
    augmented_asset = cv2.resize(asset, (new_w, new_h))
    angle = random.uniform(*rotation_range)
    center = (new_w // 2, new_h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    cos, sin = np.abs(M[0, 0]), np.abs(M[0, 1])
    nW, nH = int((new_h * sin) + (new_w * cos)), int((new_h * cos) + (new_w * sin))
    M[0, 2] += (nW / 2) - center[0]
    M[1, 2] += (nH / 2) - center[1]
    augmented_asset = cv2.warpAffine(augmented_asset, M, (nW, nH))
    if random.random() < flip_chance:
        augmented_asset = cv2.flip(augmented_asset, 1)
    return augmented_asset

================================================
FILE: data_loader/detector_loader.py
================================================

# æ–‡ä»¶: data_loader/detector_loader.py (V4.0 - é²æ£’æ€§æ¸…ç†æœ€ç»ˆç‰ˆ)
import sys
import json
import shutil
from pathlib import Path
from tqdm import tqdm
import numpy as np
from sklearn.model_selection import train_test_split
from typing import List, Dict
import yaml

# ç¡®ä¿èƒ½å¯¼å…¥utilsæ¨¡å—
PROJECT_ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(PROJECT_ROOT))
from utils.constants import get_class_maps_from_yolo_config

def build_yolo_dataset(config: Dict):
    # ... (æ­¤å‡½æ•°çš„ä¸ŠåŠéƒ¨åˆ†å®Œå…¨ä¸å˜ï¼Œä» data_paths åˆ° train_test_split) ...
    data_paths = config['data_paths']
    source_dir = Path(data_paths['detector_source_dir'])
    output_dir = Path(data_paths['detector_output_dir'])
    val_split_ratio = 0.2

    print(f"--- [æ•°æ®æ„å»º] å¼€å§‹å¤„ç†æºæ•°æ®: {source_dir} ---")
    
    if not source_dir.is_dir():
        print(f"âš ï¸ è­¦å‘Š: æºæ•°æ®ç›®å½• {source_dir} ä¸å­˜åœ¨ï¼Œè·³è¿‡æ•°æ®å‡†å¤‡ã€‚")
        return

    task_config = config['tasks']['detector']
    yolo_config_filename = task_config['yolo_config_path']
    yolo_config_path = PROJECT_ROOT / 'configs' / yolo_config_filename
    
    try:
        CLASS_TO_ID, ID_TO_CLASS = get_class_maps_from_yolo_config(yolo_config_path)
    except Exception as e:
        print(f"âŒ é”™è¯¯: åŠ è½½ç±»åˆ«ä¿¡æ¯å¤±è´¥ã€‚è¯¦æƒ…: {e}")
        return

    if output_dir.exists():
        print(f"æ¸…ç†æ—§æ•°æ®é›†ç›®å½•: {output_dir}")
        shutil.rmtree(output_dir)
    (output_dir / "images/train").mkdir(parents=True, exist_ok=True); (output_dir / "images/val").mkdir(parents=True, exist_ok=True)
    (output_dir / "labels/train").mkdir(parents=True, exist_ok=True); (output_dir / "labels/val").mkdir(parents=True, exist_ok=True)

    json_files = list(source_dir.glob("*.json"))
    if not json_files:
        print(f"âŒ é”™è¯¯: åœ¨ {source_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½• .json æ–‡ä»¶ã€‚")
        return

    train_files, val_files = train_test_split(json_files, test_size=val_split_ratio, random_state=42)
    print(f"æ•°æ®é›†åˆ’åˆ†å®Œæˆ: {len(train_files)} è®­ç»ƒ, {len(val_files)} éªŒè¯ã€‚")

    # ã€é²æ£’æ€§å¢å¼ºã€‘å¢åŠ ä¸€ä¸ªé›†åˆï¼Œç”¨äºè·Ÿè¸ªæ‰€æœ‰æœªåŒ¹é…çš„æ ‡ç­¾ï¼Œé¿å…é‡å¤æ‰“å°è­¦å‘Š
    unmatched_labels_tracker = set()

    for split_name, file_list in [("train", train_files), ("val", val_files)]:
        if not file_list: continue
        for json_path in tqdm(file_list, desc=f"è½¬æ¢ {split_name} é›†"):
            image_path = json_path.with_suffix(".png")
            if not image_path.exists(): continue
            
            shutil.copy(image_path, output_dir / f"images/{split_name}/{image_path.name}")
            
            yolo_labels = convert_single_json_to_yolo(json_path, CLASS_TO_ID, unmatched_labels_tracker)
            label_path = output_dir / f"labels/{split_name}/{json_path.stem}.txt"
            with open(label_path, 'w', encoding='utf-8') as f:
                f.write("\n".join(yolo_labels))

    if unmatched_labels_tracker:
        print("\n" + "="*50)
        print("âš ï¸ [æ•°æ®æ„å»ºè­¦å‘Š] æ£€æµ‹åˆ°ä»¥ä¸‹æ ‡ç­¾æ— æ³•åŒ¹é…ï¼Œå·²è¢«è·³è¿‡:")
        for lbl in sorted(list(unmatched_labels_tracker)):
            print(f"  - '{lbl}'")
        print("="*50 + "\n")
                
    dataset_yaml_data = {'path': str(output_dir.resolve()), 'train': 'images/train', 'val': 'images/val', 'names': ID_TO_CLASS}
    dataset_yaml_path = output_dir / "dataset.yaml"
    with open(dataset_yaml_path, 'w', encoding='utf-8') as f:
        yaml.dump(dataset_yaml_data, f, sort_keys=False, allow_unicode=True)
    
    print(f"âœ… [æ•°æ®æ„å»º] æ£€æµ‹æ•°æ®é›†æ„å»ºæˆåŠŸï¼\n   è¾“å‡ºç›®å½•: {output_dir}")

def convert_single_json_to_yolo(json_path: Path, class_mapping: dict, unmatched_tracker: set) -> List[str]:
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    img_h, img_w = data['imageHeight'], data['imageWidth']
    yolo_labels = []
    for shape in data['shapes']:
        # ã€æ ¸å¿ƒä¿®æ­£ã€‘åœ¨è¿›è¡Œä»»ä½•æ¯”è¾ƒä¹‹å‰ï¼Œå¯¹æ ‡ç­¾è¿›è¡Œæ¸…ç†ï¼
        # .strip() ä¼šç§»é™¤æ‰€æœ‰å‰å¯¼å’Œå°¾éšçš„ç©ºç™½å­—ç¬¦ï¼ˆç©ºæ ¼ã€åˆ¶è¡¨ç¬¦ã€æ¢è¡Œç¬¦ç­‰ï¼‰ã€‚
        # è¿™æ˜¯æ•°æ®å¤„ç†çš„é»„é‡‘æ³•åˆ™ã€‚
        label = shape['label'].strip()
            
        if label not in class_mapping:
            if label not in unmatched_tracker:
                unmatched_tracker.add(label) # è®°å½•æœªåŒ¹é…çš„æ ‡ç­¾
            continue
        
        class_id = class_mapping[label]
        points = np.array(shape['points'])
        x_min, y_min = points.min(axis=0)
        x_max, y_max = points.max(axis=0)
        
        cx = (x_min + x_max) / 2 / img_w; cy = (y_min + y_max) / 2 / img_h
        w = (x_max - x_min) / img_w; h = (y_max - y_min) / img_h
        
        yolo_labels.append(f"{class_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}")
    
    return yolo_labels
================================================
FILE: logger/__init__.py
================================================


================================================
FILE: model/__init__.py
================================================


================================================
FILE: prepare_data.py
================================================

# æ–‡ä»¶: /home/zhz/deepl/prepare_data.py
# èŒè´£: ä¸“é—¨è´Ÿè´£è°ƒç”¨æ•°æ®åŠ è½½å™¨ï¼Œå°†åŸå§‹æ•°æ® (å¦‚.json) è½¬æ¢ä¸ºYOLOæ ¼å¼ã€‚

import argparse
import json
from pathlib import Path
import importlib

def main(config, task_name):
    task_config = config['tasks'][task_name]
    print(f"\n--- å¯åŠ¨æ•°æ®å‡†å¤‡ä»»åŠ¡: {task_config['description']} ---")
    
    data_builder_module_name = task_config['data_builder_module']
    data_builder_func_name = task_config['data_builder_func']
    
    try:
        module = importlib.import_module(data_builder_module_name)
        prepare_data_func = getattr(module, data_builder_func_name)
        prepare_data_func(config)
        print(f"\nâœ… æ•°æ®å‡†å¤‡ä»»åŠ¡ '{task_name}' å®Œæˆï¼")
    except Exception as e:
        print(f"âŒ é”™è¯¯: æ‰§è¡Œæ•°æ®å‡†å¤‡è„šæœ¬æ—¶å¤±è´¥ã€‚è¯¦æƒ…: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='MHXY AI Model Factory - Data Preparation')
    parser.add_argument('-c', '--config', default='config.json', type=str)
    parser.add_argument('-t', '--task', type=str, required=True, choices=['detector', 'classifier'])
    args = parser.parse_args()
    
    config_path = Path(args.config)
    if not config_path.is_file():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ '{config_path}'")
    else:
        config = json.loads(config_path.read_text())
        main(config, args.task)
================================================
FILE: py.py
================================================

# æ–‡ä»¶: create_digest.py (V3.0 - åŒé‡è¿‡æ»¤æœ€ç»ˆç‰ˆ)
# èŒè´£: ä¸€ä¸ªä¸“ä¸šçš„ã€å¯é…ç½®çš„ã€100%å¯é çš„æœ¬åœ°ä»£ç æå–å™¨ã€‚
#       é€šè¿‡â€œæ–‡ä»¶åé»‘åå•â€å’Œâ€œæ‰©å±•åç™½åå•â€åŒé‡è¿‡æ»¤ï¼Œç¡®ä¿è¾“å‡ºç»å¯¹çº¯å‡€ã€‚

import os
from pathlib import Path

# ==================================================================
# 1. æ ¸å¿ƒé…ç½®ï¼šå®šä¹‰åŒé‡è¿‡æ»¤è§„åˆ™
# ==================================================================

# é»‘åå•ï¼šæ— è®ºæ‰©å±•åæ˜¯ä»€ä¹ˆï¼Œéƒ½å¼ºåˆ¶æ’é™¤è¿™äº›ç‰¹å®šçš„æ–‡ä»¶å
EXCLUDE_FILENAMES = {
    "ag_environment.yml",
    "ocr_environment.yml",
    "yolo_environment.yml",
    # æœªæ¥å¯ä»¥æ·»åŠ å…¶ä»–å·²çŸ¥çš„éæ–‡æœ¬æ–‡ä»¶
}

# ç™½åå•ï¼šåªåŒ…å«è¿™äº›åç¼€åçš„æ–‡ä»¶
TARGET_EXTENSIONS = {".py", ".yml", ".yaml", ".json"}

# é»‘åå•ï¼šå½»åº•æ’é™¤è¿™äº›ç›®å½•åŠå…¶æ‰€æœ‰å†…å®¹
EXCLUDE_DIRS = {
    "__pycache__", ".git", ".idea", ".vscode", ".pytest_cache",
    "venv", ".venv", "env", "node_modules", "dist", "build",
    "site-packages", "logs", "data", "models", "tests"
}

# ==================================================================

def generate_code_digest(root_dir: Path, output_filename: str = "full_code_filtered.txt"):
    """
    éå†æŒ‡å®šç›®å½•ï¼Œé€šè¿‡åŒé‡è¿‡æ»¤ç”Ÿæˆä¸€ä¸ªçº¯å‡€çš„æ–‡æœ¬æ‘˜è¦ã€‚
    """
    print(f"ğŸš€ å¼€å§‹åˆ†æé¡¹ç›®: {root_dir}")
    
    target_files = []

    for dirpath, dirnames, filenames in os.walk(root_dir):
        dirnames[:] = [d for d in dirnames if d not in EXCLUDE_DIRS]
        
        for filename in filenames:
            # --- [æ ¸å¿ƒä¿®æ­£ï¼šåŒé‡è¿‡æ»¤é€»è¾‘] ---
            # 1. ä¼˜å…ˆæ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åœ¨é»‘åå•ä¸­
            if filename in EXCLUDE_FILENAMES:
                continue # å¦‚æœæ˜¯ï¼Œç«‹å³è·³è¿‡

            file_path = Path(dirpath) / filename
            
            # 2. å†æ£€æŸ¥æ–‡ä»¶æ‰©å±•åæ˜¯å¦åœ¨ç™½åå•ä¸­
            if file_path.suffix in TARGET_EXTENSIONS:
                target_files.append(file_path)

    target_files.sort()
    print(f"ğŸ” æ‰¾åˆ° {len(target_files)} ä¸ªæ ¸å¿ƒä»£ç /é…ç½®æ–‡ä»¶ã€‚")

    with open(output_filename, "w", encoding="utf-8") as f:
        f.write("=== é¡¹ç›®æ ¸å¿ƒæ–‡ä»¶ç»“æ„ ===\n\n")
        f.write(f"{root_dir.name}\n")
        
        tree_structure = {}
        for path in target_files:
            parts = path.relative_to(root_dir).parts
            current_level = tree_structure
            for part in parts:
                if part not in current_level: current_level[part] = {}
                current_level = current_level[part]
        
        _write_tree(f, tree_structure)
        
        f.write("\n\n=== æ ¸å¿ƒæ–‡ä»¶å†…å®¹ ===\n")
        for file_path in target_files:
            relative_path = file_path.relative_to(root_dir)
            formatted_path = str(relative_path).replace('\\', '/')
            
            f.write(f"\n================================================\n")
            f.write(f"FILE: {formatted_path}\n")
            f.write(f"================================================\n\n")
            try:
                content = file_path.read_text(encoding="utf-8", errors='ignore')
                f.write(content)
            except Exception as e:
                f.write(f"*** æ— æ³•è¯»å–æ–‡ä»¶: {e} ***\n")

    print(f"âœ… ä¸“ä¸šä»£ç æå–å®Œæˆï¼")
    print(f"æ‘˜è¦å·²ä¿å­˜åˆ°: {output_filename}")


def _write_tree(file_handle, tree_structure, prefix=""):
    entries = sorted(tree_structure.keys())
    for i, entry in enumerate(entries):
        connector = "â””â”€â”€ " if i == len(entries) - 1 else "â”œâ”€â”€ "
        file_handle.write(f"{prefix}{connector}{entry}\n")
        if tree_structure[entry]:
            new_prefix = prefix + ("    " if i == len(entries) - 1 else "â”‚   ")
            _write_tree(file_handle, tree_structure[entry], new_prefix)


if __name__ == "__main__":
    current_directory = Path.cwd()
    generate_code_digest(current_directory)
================================================
FILE: runs/yolo_events_v1_run/args.yaml
================================================

task: detect
mode: train
model: yolov8n.pt
data: /home/zhz/deepl/data/processed/yolo_events_v1_dataset/dataset.yaml
epochs: 200
time: null
patience: 30
batch: 8
imgsz: 640
save: true
save_period: -1
cache: false
device: '0'
workers: 8
project: /home/zhz/deepl/runs/
name: yolo_events_v1_run
exist_ok: true
pretrained: true
optimizer: auto
verbose: true
seed: 0
deterministic: true
single_cls: false
rect: false
cos_lr: false
close_mosaic: 10
resume: false
amp: true
fraction: 1.0
profile: false
freeze: null
multi_scale: false
overlap_mask: true
mask_ratio: 4
dropout: 0.0
val: true
split: val
save_json: false
conf: null
iou: 0.7
max_det: 300
half: false
dnn: false
plots: true
source: null
vid_stride: 1
stream_buffer: false
visualize: false
augment: false
agnostic_nms: false
classes: null
retina_masks: false
embed: null
show: false
save_frames: false
save_txt: false
save_conf: false
save_crop: false
show_labels: true
show_conf: true
show_boxes: true
line_width: null
format: torchscript
keras: false
optimize: false
int8: false
dynamic: false
simplify: true
opset: null
workspace: null
nms: false
lr0: 0.01
lrf: 0.01
momentum: 0.937
weight_decay: 0.0005
warmup_epochs: 3.0
warmup_momentum: 0.8
warmup_bias_lr: 0.1
box: 7.5
cls: 0.5
dfl: 1.5
pose: 12.0
kobj: 1.0
nbs: 64
hsv_h: 0.015
hsv_s: 0.7
hsv_v: 0.4
degrees: 0.0
translate: 0.1
scale: 0.5
shear: 0.0
perspective: 0.0
flipud: 0.0
fliplr: 0.5
bgr: 0.0
mosaic: 1.0
mixup: 0.0
cutmix: 0.0
copy_paste: 0.0
copy_paste_mode: flip
auto_augment: randaugment
erasing: 0.4
cfg: null
tracker: botsort.yaml
save_dir: /home/zhz/deepl/runs/yolo_events_v1_run

================================================
FILE: runs/yolo_synthetic_v3/args.yaml
================================================

task: detect
mode: train
model: /home/zhz/deepl/models/yolo11n.pt
data: /home/zhz/deepl/output_simple_synth/dataset.yaml
epochs: 30
time: null
patience: 10
batch: 32
imgsz: 640
save: true
save_period: -1
cache: false
device: '0'
workers: 8
project: /home/zhz/deepl/runs/
name: yolo_synthetic_v3
exist_ok: true
pretrained: true
optimizer: auto
verbose: true
seed: 0
deterministic: true
single_cls: false
rect: false
cos_lr: false
close_mosaic: 10
resume: false
amp: true
fraction: 1.0
profile: false
freeze: null
multi_scale: false
overlap_mask: true
mask_ratio: 4
dropout: 0.0
val: true
split: val
save_json: false
conf: null
iou: 0.7
max_det: 300
half: false
dnn: false
plots: true
source: null
vid_stride: 1
stream_buffer: false
visualize: false
augment: false
agnostic_nms: false
classes: null
retina_masks: false
embed: null
show: false
save_frames: false
save_txt: false
save_conf: false
save_crop: false
show_labels: true
show_conf: true
show_boxes: true
line_width: null
format: torchscript
keras: false
optimize: false
int8: false
dynamic: false
simplify: true
opset: null
workspace: null
nms: false
lr0: 0.001
lrf: 0.01
momentum: 0.937
weight_decay: 0.0005
warmup_epochs: 3.0
warmup_momentum: 0.8
warmup_bias_lr: 0.1
box: 7.5
cls: 1.0
dfl: 1.5
pose: 12.0
kobj: 1.0
nbs: 64
hsv_h: 0.015
hsv_s: 0.7
hsv_v: 0.4
degrees: 20.0
translate: 0.2
scale: 0.2
shear: 0.0
perspective: 0.0
flipud: 0.0
fliplr: 0.5
bgr: 0.0
mosaic: 1.0
mixup: 0.0
cutmix: 0.0
copy_paste: 0.0
copy_paste_mode: flip
auto_augment: randaugment
erasing: 0.4
cfg: null
tracker: botsort.yaml
save_dir: /home/zhz/deepl/runs/yolo_synthetic_v3

================================================
FILE: test.py
================================================

# æ–‡ä»¶: validate.py
# èŒè´£: åŠ è½½å¯¼å‡ºçš„ONNXæ¨¡å‹ï¼Œå¯¹éªŒè¯é›†ä¸­çš„éšæœºå›¾ç‰‡è¿›è¡Œæ¨ç†ï¼Œ
#       å¹¶å°†æ£€æµ‹ç»“æœï¼ˆè¾¹ç•Œæ¡†å’Œæ ‡ç­¾ï¼‰å¯è§†åŒ–åœ°ç»˜åˆ¶å‡ºæ¥ï¼Œä»¥ä¾›äººå·¥è¯„ä¼°ã€‚

import cv2
import numpy as np
import onnxruntime as ort
import yaml
from pathlib import Path
import random

# --- [æ ¸å¿ƒé…ç½®] ---
# æŒ‡å‘æ‚¨åˆšåˆšå¯¼å‡ºçš„ã€éœ€è¦è¢«éªŒè¯çš„æ¨¡å‹
MODEL_PATH = Path("saved/models/yolo_v1.onnx")

# æŒ‡å‘æ•°æ®å‡†å¤‡é˜¶æ®µç”Ÿæˆçš„ dataset.yaml æ–‡ä»¶ï¼Œä»¥æ‰¾åˆ°éªŒè¯é›†å’Œç±»åˆ«å
DATASET_YAML_PATH = Path("data/processed/synthetic_locator_dataset/dataset.yaml") 

# åœ¨æ­¤ç›®å½•ä¸­æŸ¥çœ‹æ‚¨æ¨¡å‹çš„â€œç­”å·â€
OUTPUT_DIR = Path("validation_results")

# --- [æ¨ç†è¶…å‚æ•°] ---
# æ¨¡å‹è¾“å…¥çš„å›¾åƒå°ºå¯¸
INPUT_WIDTH = 640
INPUT_HEIGHT = 640

# åªæœ‰å½“æ¨¡å‹çš„é¢„æµ‹ç½®ä¿¡åº¦é«˜äºæ­¤é˜ˆå€¼æ—¶ï¼Œæ‰ä¼šè¢«è®¤ä¸ºæ˜¯æœ‰æ•ˆæ£€æµ‹
CONF_THRESHOLD = 0.1

# NMSï¼ˆéæå¤§å€¼æŠ‘åˆ¶ï¼‰çš„é˜ˆå€¼ï¼Œç”¨äºåˆå¹¶é‡å çš„æ£€æµ‹æ¡†
IOU_THRESHOLD = 0.5


class Validator:
    """
    ä¸€ä¸ªå®Œæ•´çš„ONNXæ¨¡å‹å¯è§†åŒ–éªŒè¯å™¨ã€‚
    å®ƒå°è£…äº†ä»é¢„å¤„ç†ã€æ¨ç†åˆ°åå¤„ç†å’Œå¯è§†åŒ–çš„æ‰€æœ‰æ­¥éª¤ã€‚
    """
    def __init__(self, model_path, dataset_yaml_path):
        # 1. åŠ è½½ONNXæ¨¡å‹å¹¶åˆ›å»ºæ¨ç†ä¼šè¯
        print(f"--- ğŸš€ å¯åŠ¨YOLOv1 ONNXæ¨¡å‹å¯è§†åŒ–éªŒè¯å™¨ ---")
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
        self.session = ort.InferenceSession(str(model_path), providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])
        print(f"æ¨¡å‹åŠ è½½æˆåŠŸï¼ä½¿ç”¨çš„è®¾å¤‡: {self.session.get_providers()[0]}")
        
        # 2. ä»dataset.yamlåŠ è½½ç±»åˆ«ä¿¡æ¯å’ŒéªŒè¯é›†è·¯å¾„
        print(f"æ­£åœ¨åŠ è½½æ•°æ®é›†ä¿¡æ¯: {dataset_yaml_path}")
        with open(dataset_yaml_path, 'r', encoding='utf-8') as f:
            self.dataset_info = yaml.safe_load(f)
        self.class_names = self.dataset_info['names']
        print(f"æˆåŠŸåŠ è½½ {len(self.class_names)} ä¸ªç±»åˆ«ã€‚")
        
        # 3. å‡†å¤‡éªŒè¯å›¾ç‰‡åˆ—è¡¨
        val_images_dir = dataset_yaml_path.parent / self.dataset_info['val']
        self.val_image_paths = list(val_images_dir.glob("*.png")) + list(val_images_dir.glob("*.jpg"))
        print(f"åœ¨éªŒè¯é›†ä¸­æ‰¾åˆ° {len(self.val_image_paths)} å¼ å›¾ç‰‡ã€‚")

    def run_validation(self, num_images_to_test=5):
        """
        æ‰§è¡ŒéªŒè¯æµç¨‹ã€‚
        """
        if not self.val_image_paths:
            print("âŒ é”™è¯¯: éªŒè¯é›†ä¸­æ²¡æœ‰ä»»ä½•å›¾ç‰‡ï¼Œæ— æ³•è¿›è¡ŒéªŒè¯ã€‚")
            return
            
        OUTPUT_DIR.mkdir(exist_ok=True)
        print(f"\n--- å¼€å§‹éšæœºæŠ½å– {num_images_to_test} å¼ å›¾ç‰‡è¿›è¡ŒéªŒè¯ ---")
        print(f"ç»“æœå°†ä¿å­˜åœ¨: {OUTPUT_DIR.resolve()}")

        # éšæœºé€‰æ‹©Nå¼ å›¾ç‰‡
        selected_images = random.sample(self.val_image_paths, min(num_images_to_test, len(self.val_image_paths)))

        for i, image_path in enumerate(selected_images):
            print(f"\n[{i+1}/{num_images_to_test}] æ­£åœ¨å¤„ç†: {image_path.name}")
            
            original_image = cv2.imread(str(image_path))
            
            # 1. é¢„å¤„ç†
            input_tensor, scale, pad_left, pad_top = self._preprocess(original_image)
            
            # 2. æ¨ç†
            model_inputs = {self.session.get_inputs()[0].name: input_tensor}
            model_outputs = self.session.run(None, model_inputs)
            
            # 3. åå¤„ç†
            boxes, scores, class_ids = self._postprocess(model_outputs[0], scale, pad_left, pad_top, original_image.shape)
            
            # 4. å¯è§†åŒ–
            result_image = self._draw_detections(original_image, boxes, scores, class_ids)
            
            # 5. ä¿å­˜ç»“æœ
            output_path = OUTPUT_DIR / f"result_{image_path.name}"
            cv2.imwrite(str(output_path), result_image)
            print(f"  -> æ£€æµ‹åˆ° {len(boxes)} ä¸ªç‰©ä½“ã€‚ç»“æœå·²ä¿å­˜è‡³: {output_path.name}")

        print("\n--- âœ… éªŒè¯å®Œæˆï¼ ---")

    def _preprocess(self, image):
        """å°†OpenCVå›¾åƒè½¬æ¢ä¸ºæ¨¡å‹æ‰€éœ€çš„è¾“å…¥å¼ é‡ã€‚"""
        h, w, _ = image.shape
        
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹å’Œå¡«å……å°ºå¯¸
        scale = min(INPUT_WIDTH / w, INPUT_HEIGHT / h)
        unpad_w, unpad_h = int(w * scale), int(h * scale)
        pad_w, pad_h = INPUT_WIDTH - unpad_w, INPUT_HEIGHT - unpad_h
        pad_left, pad_top = pad_w // 2, pad_h // 2
        
        # ç¼©æ”¾å’Œå¡«å……
        resized_img = cv2.resize(image, (unpad_w, unpad_h))
        padded_img = cv2.copyMakeBorder(resized_img, pad_top, pad_h - pad_top, pad_left, pad_w - pad_left, cv2.BORDER_CONSTANT)
        
        # è½¬æ¢ä¸ºCHWæ ¼å¼, å½’ä¸€åŒ–, å¹¶å¢åŠ Batchç»´åº¦
        input_tensor = padded_img.transpose(2, 0, 1).astype(np.float32) / 255.0
        input_tensor = np.expand_dims(input_tensor, axis=0)
        
        return input_tensor, scale, pad_left, pad_top

    def _postprocess(self, output, scale, pad_left, pad_top, original_shape):
        """è§£ç YOLOæ¨¡å‹çš„åŸå§‹è¾“å‡ºï¼Œæ‰§è¡ŒNMSï¼Œå¹¶å°†åæ ‡æ˜ å°„å›åŸå§‹å›¾åƒã€‚"""
        # [1, 72, 8400] -> [1, 8400, 72]
        output = np.transpose(output, (0, 2, 1))[0]
        
        boxes, scores, class_ids = [], [], []
        
        for row in output:
            # [cx, cy, w, h, class_prob_0, class_prob_1, ...]
            class_probs = row[4:]
            class_id = np.argmax(class_probs)
            confidence = class_probs[class_id]
            
            if confidence > CONF_THRESHOLD:
                cx, cy, w, h = row[:4]
                
                # å°†ä¸­å¿ƒç‚¹åæ ‡å’Œå®½é«˜è½¬æ¢ä¸ºå·¦ä¸Šè§’å’Œå³ä¸‹è§’åæ ‡
                x1 = int((cx - w / 2 - pad_left) / scale)
                y1 = int((cy - h / 2 - pad_top) / scale)
                x2 = int((cx + w / 2 - pad_left) / scale)
                y2 = int((cy + h / 2 - pad_top) / scale)
                
                boxes.append([x1, y1, x2 - x1, y2 - y1]) # NMSéœ€è¦ (x, y, w, h) æ ¼å¼
                scores.append(float(confidence))
                class_ids.append(class_id)
        
        # åº”ç”¨éæå¤§å€¼æŠ‘åˆ¶ (NMS)
        indices = cv2.dnn.NMSBoxes(boxes, scores, CONF_THRESHOLD, IOU_THRESHOLD)
        
        final_boxes, final_scores, final_class_ids = [], [], []
        if len(indices) > 0:
            for i in indices.flatten():
                final_boxes.append(boxes[i])
                final_scores.append(scores[i])
                final_class_ids.append(class_ids[i])
                
        return final_boxes, final_scores, final_class_ids

    def _draw_detections(self, image, boxes, scores, class_ids):
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœã€‚"""
        for box, score, class_id in zip(boxes, scores, class_ids):
            x, y, w, h = box
            
            # è·å–ç±»åˆ«åå’Œé¢œè‰²
            label = self.class_names.get(class_id, f"ID:{class_id}")
            color = (0, 255, 0) # ç»¿è‰²
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)
            
            # å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
            text = f"{label}: {score:.2f}"
            
            # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
            (text_w, text_h), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            cv2.rectangle(image, (x, y - text_h - 5), (x + text_w, y), color, -1)
            
            # ç»˜åˆ¶æ ‡ç­¾æ–‡å­—
            cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
            
        return image


if __name__ == "__main__":
    if not MODEL_PATH.exists():
        print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {MODEL_PATH}")
    elif not DATASET_YAML_PATH.exists():
        print(f"âŒ é”™è¯¯: æ•°æ®é›†é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {DATASET_YAML_PATH}")
    else:
        validator = Validator(MODEL_PATH, DATASET_YAML_PATH)
        validator.run_validation(num_images_to_test=10) # æ‚¨å¯ä»¥ä¿®æ”¹è¿™é‡Œæ¥æµ‹è¯•æ›´å¤šå›¾ç‰‡
================================================
FILE: tools/data_inspector.py
================================================

# æ–‡ä»¶: /home/zhz/deepl/tools/data_inspector.py
# èŒè´£: æ‰«ææŒ‡å®šçš„æ ‡æ³¨æ•°æ®æºï¼Œç»Ÿè®¡æ‰€æœ‰ç±»åˆ«çš„å®ä¾‹æ•°é‡ï¼Œ
#       å¹¶ç”Ÿæˆä¸€ä»½ç¨€ç¼ºç±»åˆ«æ¸…å•ï¼Œç”¨äºæŒ‡å¯¼åç»­çš„æ•°æ®åˆæˆã€‚

import json
from pathlib import Path
from collections import Counter
import argparse
from tqdm import tqdm

# --- [æ ¸å¿ƒé…ç½®] ---
# è„šæœ¬ä¼šè‡ªåŠ¨è®¡ç®—é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).resolve().parents[1]

# ã€è¯·ç¡®è®¤ã€‘è¿™é‡ŒæŒ‡å‘æ‚¨æ•´åˆäº†æ‰€æœ‰çœŸå®æ•°æ®çš„æºæ–‡ä»¶å¤¹
DATA_SOURCE_DIR = PROJECT_ROOT / "data/raw/real_data_combined_v1"

# ã€å¯è°ƒæ•´ã€‘å½“ä¸€ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡ä½äºæ­¤é˜ˆå€¼æ—¶ï¼Œå®ƒå°†è¢«åˆ—ä¸ºâ€œç¨€ç¼ºç±»åˆ«â€
DEFAULT_SCARCITY_THRESHOLD = 20

def analyze_class_distribution(data_dir: Path, threshold: int):
    """
    åˆ†ææŒ‡å®šç›®å½•ä¸­æ‰€æœ‰LabelMe .jsonæ–‡ä»¶çš„ç±»åˆ«åˆ†å¸ƒã€‚
    """
    print("--- ğŸš€ å¯åŠ¨æ•°æ®é›†ç±»åˆ«åˆ†å¸ƒåˆ†æå™¨ ---")
    if not data_dir.is_dir():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®æºç›®å½•: {data_dir}")
        return

    json_files = list(data_dir.glob("*.json"))
    if not json_files:
        print(f"âŒ é”™è¯¯: åœ¨ {data_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½• .json æ–‡ä»¶ã€‚")
        return

    print(f"ğŸ” æ­£åœ¨æ‰«æ {len(json_files)} ä¸ªæ ‡æ³¨æ–‡ä»¶...")

    class_counter = Counter()

    for json_path in tqdm(json_files, desc="åˆ†æè¿›åº¦"):
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            for shape in data.get('shapes', []):
                label_with_prefix = shape.get('label', '')
                if not label_with_prefix:
                    continue
                
                # ã€å…³é”®ã€‘ä½¿ç”¨ä¸è®­ç»ƒæ—¶å®Œå…¨ç›¸åŒçš„è§£æé€»è¾‘ï¼
                # ä» '1a-é™ªç»ƒ' æˆ– '1-unit-enemy-mob-å¤§æµ·é¾Ÿ' ä¸­è§£æå‡ºæ ¸å¿ƒç±»åˆ«å
                class_name = label_with_prefix.rsplit('-', 1)[-1]
                class_counter[class_name] += 1
        except Exception as e:
            print(f"\nâš ï¸ è­¦å‘Š: å¤„ç†æ–‡ä»¶ {json_path.name} æ—¶å‡ºé”™: {e}")

    if not class_counter:
        print("âŒ åˆ†æå®Œæˆï¼Œä½†æœªç»Ÿè®¡åˆ°ä»»ä½•ç±»åˆ«ã€‚è¯·æ£€æŸ¥æ‚¨çš„.jsonæ–‡ä»¶å†…å®¹ã€‚")
        return
        
    print("\n" + "="*80)
    print("--- âœ… æ•°æ®é›†ç±»åˆ«åˆ†å¸ƒåˆ†ææŠ¥å‘Š ---")
    print(f"   - æ‰«æç›®å½•: {data_dir}")
    print(f"   - æ€»è®¡å‘ç° {len(class_counter)} ä¸ªç‹¬ç«‹ç±»åˆ«ã€‚")
    print("="*80)

    # 1. æ‰“å°å®Œæ•´çš„ç±»åˆ«åˆ†å¸ƒæƒ…å†µ
    print("\n--- [å®Œæ•´ç±»åˆ«åˆ†å¸ƒ] (æŒ‰æ•°é‡é™åº) ---")
    print(f"{'æ’å':<5} | {'ç±»åˆ«åç§°':<20} | {'å®ä¾‹æ•°é‡':<10}")
    print("-" * 45)
    for i, (class_name, count) in enumerate(class_counter.most_common()):
        print(f"{i+1:<5} | {class_name:<20} | {count:<10}")

    # 2. ç­›é€‰å¹¶æ‰“å°ç¨€ç¼ºç±»åˆ«æ¸…å•
    print("\n" + "="*80)
    print(f"--- [ç¨€ç¼ºç±»åˆ«æ¸…å•] (æ ·æœ¬æ•° < {threshold}) ---")
    print("="*80)
    
    scarce_classes = []
    for class_name, count in sorted(class_counter.items(), key=lambda item: item[1]):
        if count < threshold:
            scarce_classes.append(class_name)
            print(f"   - {class_name:<20} | ä»…æœ‰ {count} ä¸ªæ ·æœ¬")

    if not scarce_classes:
        print("ğŸ‰ æ­å–œï¼æ²¡æœ‰å‘ç°ä»»ä½•ä½äºé˜ˆå€¼çš„ç¨€ç¼ºç±»åˆ«ã€‚")
    
    # 3. è¾“å‡ºæœ€ç»ˆå¯ç”¨çš„æ¸…å•
    print("\n" + "="*80)
    print("--- ğŸ“‹ [æœ€ç»ˆç¨€ç¼ºç±»åˆ«æ¸…å•] (å¯ç›´æ¥ç”¨äºæŒ‡å¯¼æ•°æ®åˆæˆ) ---")
    print("="*80)
    print(scarce_classes)
    print("\n--- åˆ†æå®Œæˆ ---")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="åˆ†æLabelMeæ•°æ®é›†çš„ç±»åˆ«åˆ†å¸ƒå¹¶æ‰¾å‡ºç¨€ç¼ºç±»åˆ«ã€‚")
    parser.add_argument(
        '-t', '--threshold', 
        type=int, 
        default=DEFAULT_SCARCITY_THRESHOLD,
        help=f"å®šä¹‰ç¨€ç¼ºç±»åˆ«çš„æ•°é‡é˜ˆå€¼ (é»˜è®¤: {DEFAULT_SCARCITY_THRESHOLD})"
    )
    args = parser.parse_args()
    
    analyze_class_distribution(DATA_SOURCE_DIR, args.threshold)
================================================
FILE: tools/data_synthesizer.py
================================================

# æ–‡ä»¶: /home/zhz/deepl/tools/data_synthesizer.py (V3.3 - æŒ‰æ¸…å•è½®è¯¢æœ€ç»ˆç‰ˆ)
# èŒè´£: ä¸¥æ ¼æŒ‰ç…§ç¨€ç¼ºç±»åˆ«æ¸…å•è¿›è¡Œè½®è¯¢ç”Ÿæˆï¼Œç¡®ä¿æ¯ä¸ªç¨€ç¼ºç±»åˆ«éƒ½æœ‰å……è¶³çš„æ ·æœ¬ã€‚

import cv2
import numpy as np
import yaml
from pathlib import Path
import random
import shutil
from tqdm import tqdm
import sys
import json
from itertools import cycle

# --- è·¯å¾„è®¾ç½®ä¸æ¨¡å—å¯¼å…¥ ---
PROJECT_ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(PROJECT_ROOT))
from utils.constants import CLASS_TO_ID, ID_TO_CLASS

# --- è¾…åŠ©å‡½æ•° (ä¿æŒä¸å˜) ---
def paste_foreground(bg_rgba, fg_rgba, pos):
    x, y = int(pos[0]), int(pos[1])
    fg_h, fg_w = fg_rgba.shape[:2]
    bg_h, bg_w = bg_rgba.shape[:2]
    x_start_on_bg = max(x, 0); y_start_on_bg = max(y, 0)
    x_end_on_bg = min(x + fg_w, bg_w); y_end_on_bg = min(y + fg_h, bg_h)
    if x_start_on_bg >= x_end_on_bg or y_start_on_bg >= y_end_on_bg: return bg_rgba
    fg_x_start = x_start_on_bg - x; fg_y_start = y_start_on_bg - y
    fg_x_end = x_end_on_bg - x; fg_y_end = y_end_on_bg - y
    fg_cropped = fg_rgba[fg_y_start:fg_y_end, fg_x_start:fg_x_end]
    bg_roi = bg_rgba[y_start_on_bg:y_end_on_bg, x_start_on_bg:x_end_on_bg]
    fg_alpha = fg_cropped[:, :, 3] / 255.0
    alpha_mask = np.dstack([fg_alpha] * 3)
    blended_rgb = (fg_cropped[:, :, :3] * alpha_mask) + (bg_roi[:, :, :3] * (1 - alpha_mask))
    bg_roi[:, :, :3] = blended_rgb.astype(bg_rgba.dtype)
    return bg_rgba

# --- ä¸»åˆæˆå™¨ç±» ---
class DataSynthesizer:
    def __init__(self, config_path, synth_config_path, scarce_class_list):
        with open(config_path, 'r', encoding='utf-8') as f: self.config = json.load(f)
        with open(synth_config_path, 'r', encoding='utf-8') as f: self.synth_config = yaml.safe_load(f)
        
        self.scarce_classes = scarce_class_list
        # ã€æ ¸å¿ƒã€‘åˆ›å»ºä¸€ä¸ªæ— é™å¾ªç¯çš„è¿­ä»£å™¨ï¼Œç”¨äºè½®è¯¢ç¨€ç¼ºç±»åˆ«
        self.scarce_class_cycler = cycle(self.scarce_classes)

        self.paths = self.config['data_paths']
        self.assets_dir = Path(self.paths['synthetic_assets_dir'])
        self.bg_dir = Path(self.paths['synthetic_backgrounds_dir'])
        self.output_dir = Path(self.paths['synthetic_output_dir'])
        
        self.assets = self._load_assets()
        self.backgrounds = self._load_backgrounds()
        # ã€æ ¸å¿ƒã€‘æŒ‰ç±»åˆ«å‰ç¼€å¯¹ç´ ækeyè¿›è¡Œé¢„åˆ†ç±»ï¼Œæ–¹ä¾¿æŸ¥æ‰¾
        self.asset_keys_by_prefix = self._classify_asset_keys()

    def _load_assets(self):
        # ... (æ­¤å‡½æ•°ä¿æŒ V3.1 ç‰ˆæœ¬ä¸å˜) ...
        print("--- æ­£åœ¨åŠ è½½èµ„äº§åº“... ---")
        assets = {}
        asset_files = list(self.assets_dir.glob("**/*.png"))
        if not asset_files: raise FileNotFoundError(f"é”™è¯¯ï¼šåœ¨èµ„äº§ç›®å½• {self.assets_dir} ä¸­æ‰¾ä¸åˆ°ä»»ä½• .png æ–‡ä»¶ã€‚")
        for path in tqdm(asset_files, desc="åŠ è½½å‰æ™¯èµ„äº§"):
            full_key = path.parent.name
            asset_img = cv2.imread(str(path), cv2.IMREAD_UNCHANGED)
            if asset_img is None or len(asset_img.shape) < 3 or asset_img.shape[2] != 4: continue
            if full_key not in assets: assets[full_key] = []
            assets[full_key].append(asset_img)
        print(f"âœ… æˆåŠŸåŠ è½½ {len(assets)} ä¸ªç±»åˆ«çš„èµ„äº§ã€‚")
        return assets

    def _load_backgrounds(self):
        # ... (æ­¤å‡½æ•°ä¿æŒ V3.1 ç‰ˆæœ¬ä¸å˜) ...
        print("--- æ­£åœ¨åŠ è½½èƒŒæ™¯åº“... ---")
        backgrounds = {}
        for bg_type in ['combat', 'ui']:
            backgrounds[bg_type] = []
            bg_paths = list((self.bg_dir / bg_type).glob("*.png"))
            for path in bg_paths:
                img = cv2.imread(str(path), cv2.IMREAD_UNCHANGED)
                if img is None: continue
                if len(img.shape) < 3 or img.shape[2] == 3: img = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)
                backgrounds[bg_type].append(img)
        print(f"âœ… æˆåŠŸåŠ è½½ {len(backgrounds['combat'])} å¼ æˆ˜æ–—èƒŒæ™¯å’Œ {len(backgrounds['ui'])} å¼ UIèƒŒæ™¯ã€‚")
        return backgrounds

    def _classify_asset_keys(self):
        """å¯¹æ‰€æœ‰èµ„äº§çš„keyæŒ‰å‰ç¼€è¿›è¡Œåˆ†ç±»ï¼Œæ–¹ä¾¿å¿«é€ŸæŸ¥æ‰¾ã€‚"""
        classified_keys = {
            '1-unit-enemy': [], '1-unit-friendly-player': [], '1-unit-friendly-pet': [],
            '5-skill-player': []
        }
        for key in self.assets.keys():
            if key.startswith('1-unit-enemy'): classified_keys['1-unit-enemy'].append(key)
            elif key.startswith('1-unit-friendly-player'): classified_keys['1-unit-friendly-player'].append(key)
            elif key.startswith('1-unit-friendly-pet'): classified_keys['1-unit-friendly-pet'].append(key)
            elif key.startswith('5-skill-player'): classified_keys['5-skill-player'].append(key)
        return classified_keys
    
    def _generate_number_image(self, value: int, digit_assets: list) -> np.ndarray:
        """
        æ ¹æ®ç»™å®šçš„æ•°å€¼ï¼ŒåŠ¨æ€ç”Ÿæˆä¸€ä¸ªå¤šä½æ•°çš„å›¾åƒã€‚
        :param value: è¦ç”Ÿæˆçš„æ•°å­—ï¼Œä¾‹å¦‚ 378
        :param digit_assets: åŒ…å« 0-9 å•ä¸ªæ•°å­—å›¾åƒçš„åˆ—è¡¨
        :return: æ‹¼æ¥å¥½çš„ã€åŒ…å«æ•´ä¸ªæ•°å­—çš„ RGBA å›¾åƒ
        """
        s_value = str(value)
        # ç¡®ä¿æˆ‘ä»¬èƒ½æ­£ç¡®åœ°æ ¹æ®æ•°å­—æ‰¾åˆ°å¯¹åº”çš„å›¾ç‰‡
        # å‡è®¾ digit_assets[0] æ˜¯ 0.png, digit_assets[1] æ˜¯ 1.png ...
        digit_images = [digit_assets[int(d)] for d in s_value]

        total_width = sum(img.shape[1] for img in digit_images)
        max_height = max(img.shape[0] for img in digit_images)

        stitched_image = np.zeros((max_height, total_width, 4), dtype=np.uint8)

        current_x = 0
        for img in digit_images:
            h, w = img.shape[:2]
            # å°†æ¯ä¸ªæ•°å­—ç”»åœ¨åº•éƒ¨å¯¹é½
            y_offset = max_height - h
            stitched_image[y_offset:y_offset+h, current_x:current_x+w] = img
            current_x += w
            
        return stitched_image


    def generate(self):
        # ... (æ­¤å‡½æ•°ä¿æŒ V3.1 ç‰ˆæœ¬ä¸å˜) ...
        print(f"--- [æ•°æ®åˆæˆ] å¼€å§‹ç”Ÿæˆæ•°æ®é›†è‡³: {self.output_dir} ---")
        if self.output_dir.exists(): shutil.rmtree(self.output_dir)
        img_train_dir = self.output_dir / "images/train"; lbl_train_dir = self.output_dir / "labels/train"
        img_val_dir = self.output_dir / "images/val"; lbl_val_dir = self.output_dir / "labels/val"
        img_train_dir.mkdir(parents=True); lbl_train_dir.mkdir(parents=True)
        img_val_dir.mkdir(parents=True); lbl_val_dir.mkdir(parents=True)
        num_to_generate = self.synth_config['num_images_to_generate']
        val_split_ratio = 0.1
        num_val = int(num_to_generate * val_split_ratio)
        for i in tqdm(range(num_to_generate), desc="ç”Ÿæˆåˆæˆå›¾åƒ"):
            bg, yolo_labels = self._generate_single_scene()
            img_name, label_name = f"synth_scarce_{i:06d}.png", f"synth_scarce_{i:06d}.txt"
            target_img_dir = img_val_dir if i < num_val else img_train_dir
            target_lbl_dir = lbl_val_dir if i < num_val else lbl_train_dir
            cv2.imwrite(str(target_img_dir / img_name), cv2.cvtColor(bg, cv2.COLOR_BGRA2BGR))
            with open(target_lbl_dir / label_name, 'w', encoding='utf-8') as f:
                f.write("\n".join(yolo_labels))
        self._create_dataset_yaml()
        print(f"âœ… [æ•°æ®åˆæˆ] ä»»åŠ¡å®Œæˆï¼")
    
    # --- ã€æ ¸å¿ƒé‡æ„ã€‘ç”Ÿæˆé€»è¾‘ ---
    def _generate_single_scene(self):
        bg = random.choice(self.backgrounds['combat']).copy()
        self.current_yolo_labels = []

        # ã€æ ¸å¿ƒç­–ç•¥ã€‘ä»ç¨€ç¼ºç±»åˆ«æ¸…å•ä¸­è½®æµå–å‡ºä¸€ä¸ªä½œä¸ºæœ¬å›¾çš„ä¸»è§’
        target_class_name = next(self.scarce_class_cycler)
        
        # æŸ¥æ‰¾è¿™ä¸ªä¸»è§’å¯¹åº”çš„å®Œæ•´ç´ ækey (e.g., 'è¡€æ¡' -> '2-status-healthbar-è¡€æ¡')
        target_asset_key = None
        for key in self.assets.keys():
            if key.endswith(target_class_name):
                target_asset_key = key
                break
        
        # æ¸²æŸ“åœºæ™¯
        if target_asset_key:
            if target_asset_key.startswith('1-unit'): # å¦‚æœä¸»è§’æ˜¯ä½œæˆ˜å•ä½
                self._place_units_with_target(bg, target_asset_key)
            elif target_asset_key.startswith('5-skill'): # å¦‚æœä¸»è§’æ˜¯æŠ€èƒ½
                self._place_units_and_ui_with_target_skill(bg, target_asset_key)
            else: # å…¶ä»–ç±»åˆ«ï¼ˆå¦‚è¡€æ¡ã€æ•°å€¼ã€ç‰©å“ç­‰ï¼‰
                # ç®€åŒ–å¤„ç†ï¼šå…ˆæ”¾ç½®å¸¸è§„ä½œæˆ˜å•ä½ä½œä¸ºâ€œèƒŒæ™¯æ¿â€
                self._place_units_in_formation(bg)
                # ç„¶åæƒ³åŠæ³•æ”¾ç½®ä¸»è§’ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®ç±»åˆ«è¿›ä¸€æ­¥ç»†åŒ–è§„åˆ™ï¼‰
                # ä¾‹å¦‚ï¼Œå¦‚æœæ˜¯è¡€æ¡ï¼Œå°±å¼ºåˆ¶é™„åŠ ç»™ä¸€ä¸ªå‹æ–¹å•ä½
                if target_class_name == 'è¡€æ¡':
                    # (æ­¤å¤„çœç•¥å¼ºåˆ¶é™„åŠ è¡€æ¡çš„é€»è¾‘)
                    pass

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¸»è§’ç´ ææˆ–è§„åˆ™ï¼Œåˆ™æŒ‰å¸¸è§„æ–¹å¼ç”Ÿæˆ
        else:
            self._place_units_in_formation(bg)
            if self.synth_config['ui_occlusion']['enabled'] and random.random() < self.synth_config['ui_occlusion']['probability']:
                self._apply_ui_occlusion(bg)

        return bg, self.current_yolo_labels

    def _place_units_with_target(self, bg, target_unit_key):
        """ç”Ÿæˆä¸€å¼ å¿…é¡»åŒ…å« target_unit_key çš„æˆ˜æ–—åœºæ™¯ã€‚"""
        # 1. æ”¾ç½®å…¶ä»–éšæœºå•ä½ä½œä¸ºé™ªè¡¬
        self._place_units_in_formation(bg, exclude_key=target_unit_key)
        # 2. åœ¨ä¸€ä¸ªéšæœºçš„ã€åˆé€‚çš„æ§½ä½ï¼Œå¼ºåˆ¶æ”¾ç½®ä¸»è§’å•ä½
        slots = self.synth_config['placement_rules']['formation_slots']
        if 'enemy' in target_unit_key:
            target_slot = random.choice(slots['enemy_back'] + slots['enemy_front'])
        else:
            target_slot = random.choice(slots['friendly_back'] + slots['friendly_front'])
        self._place_single_unit(bg, target_unit_key, target_slot)

    def _place_units_and_ui_with_target_skill(self, bg, target_skill_key):
        """ç”Ÿæˆä¸€å¼ å¿…é¡»åŒ…å« target_skill_key çš„UIé®æŒ¡åœºæ™¯ã€‚"""
        # 1. å…ˆæ”¾ç½®ä½œæˆ˜å•ä½
        self._place_units_in_formation(bg)
        # 2. å¼ºåˆ¶åº”ç”¨UIé®æŒ¡ï¼Œå¹¶ç¡®ä¿ä¸»è§’æŠ€èƒ½å‡ºç°
        self._apply_ui_occlusion(bg, force_skill_key=target_skill_key)

    def _place_units_in_formation(self, bg, exclude_key=None):
        # ... (æ­¤å‡½æ•°ä¸V3.1ç‰ˆæœ¬åŸºæœ¬ä¸€è‡´, åªæ˜¯å¢åŠ äº†exclude_keyå‚æ•°) ...
        cfg = self.synth_config
        enemy_keys = [k for k in self.asset_keys_by_prefix['1-unit-enemy'] if k != exclude_key]
        player_keys = [k for k in self.asset_keys_by_prefix['1-unit-friendly-player'] if k != exclude_key]
        pet_keys = [k for k in self.asset_keys_by_prefix['1-unit-friendly-pet'] if k != exclude_key]
        if not enemy_keys or not player_keys or not pet_keys: return
        num_enemies = random.randint(cfg['unit_density']['min_enemy_units'], cfg['unit_density']['max_enemy_units'])
        enemy_slots = cfg['placement_rules']['formation_slots']['enemy_back'] + cfg['placement_rules']['formation_slots']['enemy_front']
        random.shuffle(enemy_slots)
        for i in range(min(num_enemies, len(enemy_slots))):
            self._place_single_unit(bg, random.choice(enemy_keys), enemy_slots[i])
        self._place_single_unit(bg, random.choice(player_keys), random.choice(cfg['placement_rules']['formation_slots']['friendly_back']))
        self._place_single_unit(bg, random.choice(pet_keys), random.choice(cfg['placement_rules']['formation_slots']['friendly_front']))

    def _place_single_unit(self, bg, unit_key, roi):
        # ... (æ­¤å‡½æ•°ä¸V3.1ç‰ˆæœ¬å®Œå…¨ä¸€è‡´) ...
        unit_asset = random.choice(self.assets[unit_key]).copy()
        if 'friendly' in unit_key: unit_asset = cv2.flip(unit_asset, 1)
        h, w = unit_asset.shape[:2]
        x1, y1, x2, y2 = roi
        place_x = random.randint(x1, x2)
        place_y = random.randint(y1, y2)
        top_left_x = place_x - w // 2
        top_left_y = place_y - h
        bg = paste_foreground(bg, unit_asset, (top_left_x, top_left_y))
        unit_box = (top_left_x, top_left_y, top_left_x + w, top_left_y + h)
        self._add_yolo_label_and_events(bg, unit_key, unit_box)

    def _add_yolo_label_and_events(self, bg, unit_key, unit_box):
        # --- æ·»åŠ å•ä½æœ¬èº«çš„æ ‡ç­¾ (é€»è¾‘ä¸å˜) ---
        class_name = unit_key.rsplit('-', 1)[-1]
        if class_name in CLASS_TO_ID: self._add_yolo_label(class_name, unit_box)
        
        # --- å…³è”è¡€æ¡ (é€»è¾‘ä¸å˜) ---
        hb_cfg = self.synth_config['healthbar_association']
        if 'friendly' in unit_key and hb_cfg['enabled'] and random.random() < hb_cfg['probability']:
            if '2-status-healthbar-è¡€æ¡' in self.assets:
                healthbar_asset = random.choice(self.assets['2-status-healthbar-è¡€æ¡'])
                hb_h, hb_w = healthbar_asset.shape[:2]
                unit_center_x = (unit_box[0] + unit_box[2]) / 2
                hb_x = int(unit_center_x - hb_w / 2)
                hb_y = int(unit_box[1] + hb_cfg['vertical_offset'])
                bg = paste_foreground(bg, healthbar_asset, (hb_x, hb_y))
                self._add_yolo_label('è¡€æ¡', (hb_x, hb_y, hb_x + hb_w, hb_y + hb_h))

        # --- ã€æ ¸å¿ƒå‡çº§ V4ã€‘å…³è”æ‚¬æµ®æ•°å€¼ (æ”¯æŒä¼¤å®³ä¸æ²»ç–—) ---
        num_cfg = self.synth_config['damage_number_association']
        # é¦–å…ˆï¼Œåˆ¤æ–­æœ¬æ¬¡æ˜¯å¦è¦ç”Ÿæˆæ‚¬æµ®æ•°å€¼
        if not (num_cfg['enabled'] and random.random() < num_cfg['probability']):
            return # å¦‚æœä¸ç”Ÿæˆï¼Œåˆ™æå‰ç»“æŸå‡½æ•°

        # 1. ã€æ–°å¢ã€‘æ ¹æ®é…ç½®çš„æ¦‚ç‡ï¼Œå†³å®šæ˜¯ç”Ÿæˆæ²»ç–—(heal)è¿˜æ˜¯ä¼¤å®³(damage)
        heal_prob = num_cfg.get('heal_probability', 0.3) # å¦‚æœé…ç½®é‡Œæ²¡å†™ï¼Œé»˜è®¤30%æ¦‚ç‡
        is_heal = random.random() < heal_prob
        
        # æ ¹æ®å†³å®šï¼Œé€‰æ‹©æ­£ç¡®çš„â€œé›¶ä»¶ç›’â€
        digit_assets = None
        if is_heal and '3-digits-heal' in self.assets:
            digit_assets = self.assets['3-digits-heal']
        elif not is_heal and '3-digits-damage' in self.assets:
            digit_assets = self.assets['3-digits-damage']
        
        # å¦‚æœå¯¹åº”çš„é›¶ä»¶ç›’ä¸å­˜åœ¨ï¼Œåˆ™æ— æ³•ç»§ç»­
        if digit_assets is None:
            return

        # 2. æŒ‰ 3:4:3 æƒé‡ç”Ÿæˆ2ã€3ã€4ä½æ•° (é€»è¾‘ä¸å˜)
        num_digits_choices = [2, 3, 4]; weights = [0.3, 0.4, 0.3]
        chosen_digits = random.choices(num_digits_choices, weights=weights, k=1)[0]
        if chosen_digits == 2: min_val, max_val = 10, 99
        elif chosen_digits == 3: min_val, max_val = 100, 999
        else: min_val, max_val = 1000, 9999
        value_to_generate = random.randint(min_val, max_val)
        
        # 3. åŠ¨æ€ç”Ÿæˆæ•°å€¼å›¾ç‰‡ (é€»è¾‘ä¸å˜)
        number_image = self._generate_number_image(value_to_generate, digit_assets)
        num_h, num_w = number_image.shape[:2]

        # 4. èº«ä½“ä¸­å¿ƒå®šä½é€»è¾‘ (é€»è¾‘ä¸å˜)
        unit_x1, unit_y1, unit_x2, unit_y2 = unit_box
        unit_w = unit_x2 - unit_x1
        unit_h = unit_y2 - unit_y1
        unit_center_x = unit_x1 + unit_w / 2
        unit_center_y = unit_y1 + unit_h / 2
        horizontal_jitter = unit_w * random.uniform(-0.1, 0.1)
        num_x = int(unit_center_x - num_w / 2 + horizontal_jitter)
        jitter_range = (unit_h / 2) * num_cfg.get('body_center_jitter_ratio', 0.4)
        vertical_jitter = random.uniform(-jitter_range, jitter_range)
        num_y = int(unit_center_y - num_h / 2 + vertical_jitter)

        # 5. ç²˜è´´å¹¶æ‰“æ ‡ç­¾ (é€»è¾‘ä¸å˜)
        # æ— è®ºçº¢è‰²è¿˜æ˜¯ç»¿è‰²ï¼Œå®ƒä»¬çš„ç±»åˆ«éƒ½æ˜¯â€œæ‚¬æµ®æ•°å€¼â€
        bg = paste_foreground(bg, number_image, (num_x, num_y))
        self._add_yolo_label('æ‚¬æµ®æ•°å€¼', (num_x, num_y, num_x + num_w, num_y + num_h))

    def _apply_ui_occlusion(self, bg, force_skill_key=None):
        # ... (æ­¤å‡½æ•°ä¸V3.2ç‰ˆæœ¬åŸºæœ¬ä¸€è‡´, åªæ˜¯å¢åŠ äº†force_skill_keyå‚æ•°) ...
        cfg = self.synth_config['ui_occlusion']
        if not self.backgrounds['ui']: return
        panel_asset = random.choice(self.backgrounds['ui']).copy()
        panel_roi = cfg['panel_roi']
        skill_keys = [k for k in self.asset_keys_by_prefix['5-skill-player'] if k != force_skill_key]
        random.shuffle(skill_keys)
        if force_skill_key: skill_keys.insert(0, force_skill_key) # ç¡®ä¿ä¸»è§’æŠ€èƒ½è¢«ä¼˜å…ˆæ”¾ç½®
        slots = cfg['skill_slots_relative']
        num_to_show = random.randint(*cfg['num_skills_to_show_range'])
        for i in range(min(num_to_show, len(slots), len(skill_keys))):
            skill_asset = random.choice(self.assets[skill_keys[i]])
            slot_roi = slots[i]
            asset_h, asset_w = skill_asset.shape[:2]
            x_range_max = slot_roi[2] - asset_w
            y_range_max = slot_roi[3] - asset_h
            place_x = slot_roi[0] if slot_roi[0] >= x_range_max else random.randint(slot_roi[0], x_range_max)
            place_y = slot_roi[1] if slot_roi[1] >= y_range_max else random.randint(slot_roi[1], y_range_max)
            panel_asset = paste_foreground(panel_asset, skill_asset, (place_x, place_y))
            global_x = panel_roi[0] + place_x
            global_y = panel_roi[1] + place_y
            self._add_yolo_label(skill_keys[i].rsplit('-', 1)[-1], 
                                (global_x, global_y, global_x + asset_w, global_y + asset_h))
        bg = paste_foreground(bg, panel_asset, (panel_roi[0], panel_roi[1]))

    # --- ã€å…³é”®ã€‘é‡æ–°æ·»åŠ è¢«è¯¯åˆ çš„ _add_yolo_label å‡½æ•° ---
    def _add_yolo_label(self, class_name, box):
        if class_name not in CLASS_TO_ID: return
        class_id = CLASS_TO_ID[class_name]
        x1, y1, x2, y2 = box
        bg_w, bg_h = self.synth_config['output_image_size']
        cx = (x1 + x2) / 2 / bg_w; cy = (y1 + y2) / 2 / bg_h
        w = (x2 - x1) / bg_w; h = (y2 - y1) / bg_h
        self.current_yolo_labels.append(f"{class_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}")

    def _create_dataset_yaml(self):
        # ... (æ­¤å‡½æ•°ä¿æŒ V3.1 ç‰ˆæœ¬ä¸å˜) ...
        dataset_yaml_data = {'path': str(self.output_dir.resolve()), 'train': 'images/train', 'val': 'images/val', 'names': ID_TO_CLASS}
        with open(self.output_dir / "dataset.yaml", 'w', encoding='utf-8') as f:
            yaml.dump(dataset_yaml_data, f, sort_keys=False, allow_unicode=True)
        print(f"âœ… å·²åˆ›å»ºæ•°æ®é›†é…ç½®æ–‡ä»¶: {self.output_dir / 'dataset.yaml'}")

if __name__ == '__main__':
    scarce_class_list_from_inspector = [
        'å¤©é¾™æ°´', 'ä¹¦ä¿¡', 'é¾™å·é›¨å‡»', 'ç¬›å­', 'ç¡®è®¤æŒ‰é’®', 'é‡‘åˆšæŠ¤æ³•', 'å”§å”§æ­ªæ­ª', 
        'æ¨æ°”è¿‡å®«', 'é›·é¸Ÿäºº', 'æ¨ªæ‰«åƒå†›', 'ç‹¡çŒ¾çš„è²”è²…', 'é€šçŸ¥æ ', 'ä¹è½¬é‡‘ä¸¹', 
        'é¬¼åˆ‡è‰', 'å‡¤å‡°', 'å¤©å°†', 'å¤§è™è ', 'åœ°ç‹±æˆ˜ç¥', 'å››å¶èŠ±', 'ä½›æ‰‹', 
        'é¾Ÿä¸ç›¸', 'ç™½ç†Š', 'ç‰›åˆ€å°è¯•', 'é«˜çº§å® ç‰©å£ç²®', 'æŠ¤å«', 'æ´å†¥è‰', 
        'æµ·æ¯›è™«', 'æ¡ƒèŠ±', 'åŒ…å­', 'èµŒå¾’', 'å® ç‰©å£ç²®', 'æ ‘æ€ª', 'é‡çŒª', 
        'ä»™ç‹æ¶', 'å·¨è›™', 'ç»¿èŠ¦ç¾¹', 'ä½›å…‰èˆåˆ©å­', 'å±±è´¼', 'æœˆè§è‰', 'çº¢ç½—ç¾¹',
        'è¡€æ¡', 'æ‚¬æµ®æ•°å€¼'
    ]
    synthesizer = DataSynthesizer(
        config_path=PROJECT_ROOT / 'config.json',
        synth_config_path=PROJECT_ROOT / 'configs/synthesis_config.yaml',
        scarce_class_list=scarce_class_list_from_inspector
    )
    synthesizer.generate()
================================================
FILE: train.py
================================================

# æ–‡ä»¶: train.py (V3 - ä¼˜é›…æ¶æ„æœ€ç»ˆç‰ˆ)
import argparse
import json
from pathlib import Path

# ã€æ ¸å¿ƒã€‘æˆ‘ä»¬åœ¨è¿™é‡Œå®šä¹‰ä¸€ä¸ªé¡¹ç›®çº§çš„çº¦å®šï¼šæ‰€æœ‰é…ç½®æ–‡ä»¶éƒ½æ”¾åœ¨ configs ç›®å½•ä¸‹
CONFIG_DIR = Path("configs")

# å¯¼å…¥ Trainer æ—¶ä¸å†éœ€è¦å¤æ‚çš„ sys.path æ“ä½œï¼Œå› ä¸ºå®ƒåº”è¯¥æ˜¯ä¸€ä¸ªå¯å®‰è£…çš„åŒ…æˆ–æœ‰æ­£ç¡®çš„ __init__.py
from trainer.trainer import Trainer

def main(config, task_name):
    task_config = config['tasks'][task_name]
    print(f"\n--- å¯åŠ¨è®­ç»ƒä»»åŠ¡: {task_config['description']} ---")

    # [æ­¥éª¤ 1/1] åˆå§‹åŒ–å¹¶å¯åŠ¨è®­ç»ƒå™¨
    print("\n[Step 1/1] åˆå§‹åŒ–å¹¶å¯åŠ¨è®­ç»ƒå™¨...")
    
    # ã€æ ¸å¿ƒä¿®æ­£ã€‘è·¯å¾„æ‹¼æ¥çš„é€»è¾‘è¢«ç»Ÿä¸€æ”¶å½’äºæ­¤ï¼Œå¥å£®ä¸”ä¸æ˜“å‡ºé”™
    # 1. ä»ä¸»é…ç½®ä¸­è·å–çº¯ç²¹çš„æ–‡ä»¶å
    config_filename = task_config['yolo_config_path']
    # 2. ä¸æˆ‘ä»¬çº¦å®šçš„é…ç½®ç›®å½•è¿›è¡Œæ‹¼æ¥
    yolo_config_path = CONFIG_DIR / config_filename

    trainer_instance = Trainer(yolo_config_path)
    trainer_instance.train()

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='MHXY AI Model Factory')
    parser.add_argument('-c', '--config', default='config.json', type=str,
                      help='Path to the main configuration file (default: config.json)')
    parser.add_argument('-t', '--task', type=str, required=True, choices=['detector', 'classifier'],
                      help='Name of the task to run (detector or classifier)')
    
    args = parser.parse_args()
    
    config_path = Path(args.config)
    if not config_path.is_file():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ '{config_path}'")
    else:
        config = json.loads(config_path.read_text())
        main(config, args.task)
================================================
FILE: trainer/__init__.py
================================================


================================================
FILE: trainer/trainer.py
================================================

# æ–‡ä»¶: trainer/main_trainer.py (é‡æ„ç‰ˆ)
import yaml
from ultralytics import YOLO
from pathlib import Path
import shutil

class Trainer:
    def __init__(self, yolo_config_path: str):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨ã€‚
        :param yolo_config_path: æŒ‡å‘ç‰¹å®šä»»åŠ¡çš„YOLO .yamlé…ç½®æ–‡ä»¶çš„è·¯å¾„ã€‚
        """
        self.yolo_config_path = Path(yolo_config_path)
        if not self.yolo_config_path.is_file():
            raise FileNotFoundError(f"YOLOé…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {self.yolo_config_path}")
            
        with open(self.yolo_config_path, 'r') as f:
            self.yolo_config = yaml.safe_load(f)
        
        self.model = YOLO(self.yolo_config.get('model', 'yolo11n.pt'))

    def train(self):
        """
        ä½¿ç”¨åŠ è½½çš„é…ç½®å¯åŠ¨YOLOv8è®­ç»ƒã€‚
        """
        print(f"--- ä½¿ç”¨é…ç½®æ–‡ä»¶ '{self.yolo_config_path.name}' å¼€å§‹è®­ç»ƒ ---")
        self.yolo_config.pop('names', None)
        self.model.train(**self.yolo_config)
        print("--- âœ… è®­ç»ƒå®Œæˆ ---")
        
        # è®­ç»ƒå®Œæˆåè‡ªåŠ¨è°ƒç”¨å¯¼å‡ºæµç¨‹
        self.export_model()

# æ–‡ä»¶: trainer/trainer.py

    def export_model(self, model_to_export=None):
        """
        ä»¥â€œé»„é‡‘æ ‡å‡†â€åŸåˆ™å¯¼å‡ºæŒ‡å®šçš„æˆ–è®­ç»ƒå¥½çš„æœ€ä½³æ¨¡å‹ä¸ºONNXæ ¼å¼ã€‚
        ã€æœ€ç»ˆä¿®æ­£ã€‘æ°¸ä¹…ç¦ç”¨ simplify=True ä»¥é¿å…ç¯å¢ƒå…¼å®¹æ€§å¯¼è‡´çš„åº•å±‚å´©æºƒã€‚
        """
        if model_to_export:
            model = YOLO(model_to_export)
            print(f"\nğŸš€ æ­£åœ¨å¯¼å‡ºæŒ‡å®šçš„æ¨¡å‹: {model_to_export}")
        else:
            model = self.model
            best_model_path = Path(model.trainer.best)
            print(f"\nğŸ† è®­ç»ƒå‡ºçš„æœ€ä½³æ¨¡å‹: {best_model_path}")
        
        task_type = self.yolo_config.get('task', 'detect')
        
        if task_type == 'detect':
            print("ğŸš€ æ­£åœ¨ä»¥ã€æœ€é«˜å…¼å®¹æ€§ã€‘æ¨¡å¼å¯¼å‡ºæ£€æµ‹å™¨æ¨¡å‹...")
            target_name = "yolov11.onnx"
            export_params = {
                'format': 'onnx',
                'opset': 13,         
                'simplify': False,  # ã€æ ¸å¿ƒä¿®æ­£ã€‘ç¦ç”¨æ­¤é¡¹
                'nms': False,       
                'dynamic': False,     
                'batch': 1,          
                'imgsz': self.yolo_config.get('imgsz', 640)
            }
        # ... (classify éƒ¨åˆ†ä¿æŒä¸å˜)
        elif task_type == 'classify':
            print("ğŸš€ æ­£åœ¨å¯¼å‡ºåˆ†ç±»å™¨æ¨¡å‹...")
            target_name = "guaiwu_classifier.onnx"
            export_params = {
                'format': 'onnx',
                'opset': 12,
                'simplify': False, # ã€æ ¸å¿ƒä¿®æ­£ã€‘åŒæ ·ç¦ç”¨
                'imgsz': self.yolo_config.get('imgsz', 64)
            }
        else:
            print(f"âš ï¸ è­¦å‘Š: æœªçŸ¥çš„ä»»åŠ¡ç±»å‹ '{task_type}'ï¼Œè·³è¿‡æ¨¡å‹å¯¼å‡ºã€‚")
            return

        try:
            onnx_path = model.export(**export_params)
            target_onnx_path = Path("saved/models") / target_name
            target_onnx_path.parent.mkdir(parents=True, exist_ok=True)
            shutil.move(str(onnx_path), str(target_onnx_path))
            
            print("\n" + "="*50)
            print("âœ… å¯¼å‡ºæˆåŠŸï¼")
            print(f"   å·²ç”Ÿæˆæ¨¡å‹: {target_onnx_path}")
            print("="*50)
        except Exception as e:
            print(f"\n--- âŒ å¯¼å‡ºå¤±è´¥ï¼é”™è¯¯: {e} ---")
            import traceback
            traceback.print_exc()
================================================
FILE: utils/__init__.py
================================================


================================================
FILE: utils/constants.py
================================================

# æ–‡ä»¶: /home/zhz/deepl/utils/constants.py (V7.0 - åŠ¨æ€YAMLåŠ è½½å™¨æœ€ç»ˆç‰ˆ)
# èŒè´£: æä¾›ä¸€ä¸ªå¥å£®çš„å·¥å…·ï¼Œç”¨äºä»YOLOv8è®­ç»ƒé…ç½®æ–‡ä»¶(.yaml)ä¸­åŠ¨æ€åŠ è½½ç±»åˆ«ä¿¡æ¯ã€‚
#       æœ¬æ¨¡å—ä¸å†æ˜¯é™æ€çš„â€œäº‹å®æ¥æºâ€ï¼Œè€Œæ˜¯ä¸€ä¸ªåŠ¨æ€çš„ã€æŒ‰éœ€æœåŠ¡çš„â€œä¿¡æ¯è§£æå™¨â€ã€‚

import yaml
from pathlib import Path
from typing import Dict, Tuple, List

def get_class_maps_from_yolo_config(yolo_config_path: Path) -> Tuple[Dict[str, int], Dict[int, str]]:
    """
    ä»æŒ‡å®šçš„YOLOé…ç½®æ–‡ä»¶ä¸­è¯»å–'names'å­—æ®µï¼Œå¹¶ç”Ÿæˆç±»åˆ«åˆ°IDå’ŒIDåˆ°ç±»åˆ«çš„æ˜ å°„ã€‚

    è¯¥å‡½æ•°å…·æœ‰é«˜é²æ£’æ€§ï¼Œèƒ½å¤Ÿæ™ºèƒ½å¤„ç†ä¸¤ç§å¸¸è§çš„ 'names' æ ¼å¼:
    1. å­—å…¸æ ¼å¼ (YOLOv8 æ¨è): {0: 'cat', 1: 'dog'}
    2. åˆ—è¡¨æ ¼å¼ (æ—§ç‰ˆYOLOv5å…¼å®¹): ['cat', 'dog']

    Args:
        yolo_config_path (Path): æŒ‡å‘YOLOè®­ç»ƒé…ç½® .yaml æ–‡ä»¶çš„è·¯å¾„å¯¹è±¡ã€‚

    Returns:
        A tuple containing:
        - class_to_id (Dict[str, int]): A dictionary mapping class names to IDs.
        - id_to_class (Dict[int, str]): A dictionary mapping IDs to class names.
        
    Raises:
        FileNotFoundError: å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ã€‚
        KeyError: å¦‚æœé…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘ 'names' å­—æ®µã€‚
        ValueError: å¦‚æœ 'names' å­—æ®µä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®ã€‚
    """
    print(f"--- [ç±»åˆ«åŠ è½½] åŠ¨æ€åŠ è½½ç±»åˆ«æ¥æº: {yolo_config_path.name} ---")
    if not yolo_config_path.is_file():
        raise FileNotFoundError(f"âŒ é”™è¯¯: åŠ¨æ€ç±»åˆ«æºæ–‡ä»¶æœªæ‰¾åˆ°: {yolo_config_path}")

    with open(yolo_config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    if 'names' not in config:
        raise KeyError(f"âŒ é”™è¯¯: åœ¨ {yolo_config_path.name} ä¸­æœªæ‰¾åˆ°å…³é”®çš„ 'names' å­—æ®µã€‚")

    names_data = config['names']
    if not names_data:
        raise ValueError(f"âŒ é”™è¯¯: 'names' å­—æ®µåœ¨ {yolo_config_path.name} ä¸­ä¸ºç©ºã€‚")

    # --- æ ¸å¿ƒé€»è¾‘: æ™ºèƒ½è§£æ 'names' ---
    if isinstance(names_data, dict):
        # YOLOv8 æ ¼å¼: {0: 'name1', 1: 'name2'}
        id_to_class = dict(sorted(names_data.items())) # ç¡®ä¿IDæœ‰åº
        class_to_id = {name: i for i, name in id_to_class.items()}
    elif isinstance(names_data, list):
        # YOLOv5 å…¼å®¹æ ¼å¼: ['name1', 'name2']
        id_to_class = {i: name for i, name in enumerate(names_data)}
        class_to_id = {name: i for i, name in id_to_class.items()}
    else:
        raise TypeError(f"âŒ é”™è¯¯: 'names' å­—æ®µçš„æ ¼å¼æ— æ³•è¯†åˆ«ã€‚æœŸæœ›æ˜¯å­—å…¸æˆ–åˆ—è¡¨ï¼Œä½†å¾—åˆ°çš„æ˜¯ {type(names_data)}ã€‚")

    print(f"âœ… [ç±»åˆ«åŠ è½½] æˆåŠŸåŠ è½½ {len(id_to_class)} ä¸ªç±»åˆ«ã€‚")
    return class_to_id, id_to_class